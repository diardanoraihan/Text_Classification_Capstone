{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classification with CR Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using Multi Layer Perceptron on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10662, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simplistic , silly and tedious .</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it 's so laddish and juvenile , only teenage b...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exploitative and largely devoid of the depth o...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garbus discards the potential for pathological...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a visually flashy but narratively opaque and e...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>both exuberantly romantic and serenely melanch...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>mazel tov to a film about a family 's joyous l...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>standing in the shadows of motown is the best ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>it 's nice to see piscopo again after all thes...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>provides a porthole into that noble , tremblin...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10662 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label  split\n",
       "0                       simplistic , silly and tedious .      0  train\n",
       "1      it 's so laddish and juvenile , only teenage b...      0  train\n",
       "2      exploitative and largely devoid of the depth o...      0  train\n",
       "3      garbus discards the potential for pathological...      0  train\n",
       "4      a visually flashy but narratively opaque and e...      0  train\n",
       "...                                                  ...    ...    ...\n",
       "10657  both exuberantly romantic and serenely melanch...      1  train\n",
       "10658  mazel tov to a film about a family 's joyous l...      1  train\n",
       "10659  standing in the shadows of motown is the best ...      1  train\n",
       "10660  it 's nice to see piscopo again after all thes...      1  train\n",
       "10661  provides a porthole into that noble , tremblin...      1  train\n",
       "\n",
       "[10662 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/MR/MR.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10662 entries, 0 to 10661\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  10662 non-null  object\n",
      " 1   label     10662 non-null  int32 \n",
      " 2   split     10662 non-null  object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 208.4+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5331</td>\n",
       "      <td>5331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5331</td>\n",
       "      <td>5331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          5331   5331\n",
       "1          5331   5331"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simplistic , silly and tedious .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Word2Vec Static\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Word Embedding: Word2Vec\n",
    "\n",
    "__1. Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16448 words present from 18760 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "oov_tok = '<OOV>'\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `clean_doc` function\n",
    "__2. Define a function to clean the document called __`clean_doc()`____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(sentences, word_index):\n",
    "    clean_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower().split()\n",
    "        clean_word = []\n",
    "        for word in sentence:\n",
    "            if word in word_index:\n",
    "                clean_word.append(word)\n",
    "        clean_sentence = ' '.join(clean_word)\n",
    "        clean_sentences.append(clean_sentence)\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simplistic silly and tedious',\n",
       " \"it 's so laddish and juvenile only teenage boys could possibly find it funny\",\n",
       " 'exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences = clean_doc(sentences, word_index)\n",
    "clean_sentences[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `sentence_to_avg` function\n",
    "__3. Define a `sentence_to_avg` function__\n",
    "\n",
    "We will use this function to calculate the mean of word embedding representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Split sentence into list of lower case words (≈ 1 line)\n",
    "    words = (sentence.lower()).split()\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros(word2vec.word_vec('i').shape)\n",
    "    \n",
    "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in word_to_vec_map:\n",
    "            total += word_to_vec_map.word_vec(w)\n",
    "            count += 1\n",
    "            \n",
    "    if count!= 0:\n",
    "        avg = total/count\n",
    "    else:\n",
    "        avg\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.22558594\n",
      "-0.16699219\n",
      "0.11376953\n",
      "the mean of word embedding is:  -0.09293619791666667\n"
     ]
    }
   ],
   "source": [
    "i = word2vec.word_vec('i')[0]\n",
    "print(word2vec.word_vec('i')[0])\n",
    "j = word2vec.word_vec('am')[0]\n",
    "print(word2vec.word_vec('am')[0])\n",
    "k = word2vec.word_vec('handsome')[0]\n",
    "print(word2vec.word_vec('handsome')[0])\n",
    "mean = (i+j+k)/3\n",
    "print('the mean of word embedding is: ', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0929362 ,  0.03125   , -0.03914388,  0.09879557,  0.07088598,\n",
       "        0.03092448, -0.00651042, -0.04437256,  0.08068848,  0.07242838,\n",
       "        0.00160726, -0.10530599, -0.07389323, -0.08854166,  0.00565592,\n",
       "        0.15136719, -0.0460612 ,  0.19482422,  0.1101888 ,  0.05924479,\n",
       "       -0.18457031,  0.00716146,  0.16153972,  0.02437337, -0.01578776,\n",
       "        0.06119792, -0.25048828,  0.02799479,  0.0853475 , -0.14029948,\n",
       "        0.13688152, -0.01350911, -0.05493164, -0.01090495,  0.03352864,\n",
       "        0.09635416, -0.04239909,  0.00777181, -0.1438802 ,  0.06510416,\n",
       "        0.14560954, -0.11295573,  0.25520834,  0.08833822,  0.14339192,\n",
       "        0.037028  , -0.02832031, -0.00139872,  0.00309245, -0.17871094,\n",
       "        0.06852213,  0.07910156,  0.09513346,  0.11425781, -0.00488281,\n",
       "        0.11051432, -0.01139323, -0.08479818, -0.09277344, -0.03263346,\n",
       "       -0.00374349,  0.07977295, -0.26416016, -0.05135091,  0.06111654,\n",
       "       -0.06933594, -0.06486002,  0.18766277, -0.04826609,  0.03304036,\n",
       "        0.24267578,  0.11425781,  0.02310689,  0.06697591, -0.19010417,\n",
       "        0.03230794,  0.00317383, -0.03739421,  0.12434896,  0.1574707 ,\n",
       "       -0.05745443,  0.015625  ,  0.01456706, -0.05794271, -0.0549113 ,\n",
       "        0.0398763 , -0.01517741,  0.11263021, -0.03271484,  0.06758627,\n",
       "       -0.09594727,  0.06559245,  0.00217692,  0.03627523, -0.03776042,\n",
       "        0.02945963, -0.05960592, -0.02514648,  0.07128906, -0.04410807,\n",
       "       -0.21533203, -0.02174886, -0.05029297,  0.04264323,  0.08194987,\n",
       "        0.05502828,  0.09375   , -0.02050781,  0.04243978, -0.1439616 ,\n",
       "        0.        , -0.17805989,  0.0822347 ,  0.00140381,  0.17220052,\n",
       "       -0.08251953,  0.00450643, -0.24837239,  0.14001465,  0.01749674,\n",
       "        0.24576823, -0.06986491, -0.04370117,  0.01497396, -0.01534017,\n",
       "        0.09863281, -0.12027995,  0.14615886,  0.19580078,  0.08813477,\n",
       "       -0.2861328 , -0.0653483 , -0.03889974, -0.07784017, -0.12190755,\n",
       "       -0.04427083, -0.06233724,  0.08296712,  0.12670898,  0.1593221 ,\n",
       "        0.04296875,  0.08544922, -0.01513672,  0.        , -0.2101237 ,\n",
       "        0.11390177, -0.01127116, -0.06298828,  0.0198822 , -0.03000895,\n",
       "       -0.05118815, -0.00195312, -0.1007487 ,  0.09879557, -0.19702148,\n",
       "       -0.05611674, -0.03466797,  0.13932292, -0.0764974 , -0.00777181,\n",
       "        0.05948893,  0.11360677,  0.01757812,  0.07926432, -0.0104777 ,\n",
       "       -0.16145833,  0.17708333,  0.13507843, -0.06380209,  0.10839844,\n",
       "       -0.21500652, -0.0933431 ,  0.05853271, -0.14601643, -0.0369873 ,\n",
       "        0.02945963,  0.2747396 , -0.07006454,  0.06966146, -0.17203777,\n",
       "       -0.02294922, -0.09220377, -0.01790492, -0.0111084 , -0.03776042,\n",
       "        0.03540039, -0.03483073,  0.0764974 ,  0.07096354, -0.13916016,\n",
       "       -0.01989746,  0.06176758, -0.11336263, -0.03279241,  0.08687337,\n",
       "        0.15901692, -0.07185873,  0.02547201, -0.03220622, -0.125     ,\n",
       "       -0.12727864,  0.02563477, -0.06311035, -0.16959636, -0.10058594,\n",
       "       -0.05464681, -0.09391276,  0.06502279, -0.06184896,  0.14835612,\n",
       "       -0.1031901 ,  0.07779948, -0.06420898, -0.0892334 , -0.20214844,\n",
       "        0.13671875,  0.11507162, -0.00145467, -0.23079427, -0.04801432,\n",
       "       -0.06262207,  0.07454427,  0.0298055 , -0.01489258,  0.08854166,\n",
       "       -0.1608073 , -0.00372314, -0.056722  , -0.06841787, -0.16031902,\n",
       "        0.1538086 , -0.03597005, -0.09985352, -0.03483073,  0.07324219,\n",
       "        0.03672282,  0.03737386,  0.06705729,  0.10375977,  0.04850261,\n",
       "        0.20996094,  0.06673177,  0.03833008,  0.06363932, -0.18758138,\n",
       "       -0.10904948, -0.02693685,  0.02254232, -0.08405808,  0.02848307,\n",
       "        0.17675781,  0.01188151,  0.08610026,  0.18359375,  0.0764974 ,\n",
       "        0.03463237,  0.08015951,  0.00455729, -0.15309651,  0.00195312,\n",
       "        0.0965983 , -0.18180339, -0.02457682, -0.01757812, -0.08410645,\n",
       "        0.20092773, -0.12624104, -0.09566244, -0.03291829, -0.04532878,\n",
       "        0.04199219, -0.01635742,  0.04329427,  0.06469727,  0.04390462,\n",
       "        0.03625488, -0.04744466, -0.14420573, -0.17626953,  0.18603516,\n",
       "        0.01155599,  0.06009929, -0.02880859,  0.06738281,  0.0949707 ,\n",
       "        0.00325521, -0.07470703, -0.18782552, -0.00447591,  0.06038411,\n",
       "        0.0456543 ,  0.10611979, -0.11393229, -0.05623372, -0.03450521,\n",
       "        0.02193197, -0.12263998, -0.08158366, -0.0332845 ,  0.09596761],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the functions used in a sentence\n",
    "mysentence = 'I am handsome'\n",
    "sentence_to_avg(mysentence, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Sentence into Word2Vec Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_sentences(sentences):\n",
    "\n",
    "    encoded_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        encoded_sentence = sentence_to_avg(sentence, word2vec)\n",
    "        encoded_sentences.append(encoded_sentence)\n",
    "\n",
    "    encoded_sentences = np.array(encoded_sentences)\n",
    "    return encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10662, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.22493489, -0.03442383, -0.05810547, ..., -0.02913412,\n",
       "        -0.1258138 ,  0.20052083],\n",
       "       [ 0.02938334,  0.03513813,  0.02398427, ..., -0.06489563,\n",
       "         0.06098684,  0.04986   ],\n",
       "       [ 0.02773868,  0.08043715,  0.01731962, ..., -0.06427361,\n",
       "         0.0566128 , -0.00628303],\n",
       "       ...,\n",
       "       [ 0.04141097,  0.06443648,  0.04822679, ..., -0.02214883,\n",
       "         0.04628129, -0.03073085],\n",
       "       [ 0.03426514,  0.04058971, -0.00080566, ..., -0.01333466,\n",
       "         0.07069702, -0.06862793],\n",
       "       [ 0.04723011, -0.04642001,  0.03718844, ...,  0.01513117,\n",
       "         0.04043302,  0.05668502]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = encoded_sentences(clean_sentences)\n",
    "print(embedded_sentences.shape)\n",
    "embedded_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=50, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                15050     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 15,101\n",
      "Trainable params: 15,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model(300)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "'''\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5913 - accuracy: 0.6941 - val_loss: 0.5200 - val_accuracy: 0.7507\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5009 - accuracy: 0.7612 - val_loss: 0.4832 - val_accuracy: 0.7648\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4791 - accuracy: 0.7704 - val_loss: 0.4781 - val_accuracy: 0.7629\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4726 - accuracy: 0.7701 - val_loss: 0.4685 - val_accuracy: 0.7694\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4615 - accuracy: 0.7793 - val_loss: 0.4856 - val_accuracy: 0.7591\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4582 - accuracy: 0.7823 - val_loss: 0.4639 - val_accuracy: 0.7694\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4531 - accuracy: 0.7777 - val_loss: 0.4613 - val_accuracy: 0.7713\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4469 - accuracy: 0.7855 - val_loss: 0.4753 - val_accuracy: 0.7713\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4440 - accuracy: 0.7842 - val_loss: 0.4635 - val_accuracy: 0.7666\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4463 - accuracy: 0.7866 - val_loss: 0.4578 - val_accuracy: 0.7751\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.4638 - val_accuracy: 0.7732\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4376 - accuracy: 0.7891 - val_loss: 0.4693 - val_accuracy: 0.7694\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4351 - accuracy: 0.7911 - val_loss: 0.4602 - val_accuracy: 0.7769\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4332 - accuracy: 0.7959 - val_loss: 0.4600 - val_accuracy: 0.7788\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4313 - accuracy: 0.7973 - val_loss: 0.4590 - val_accuracy: 0.7760\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4300 - accuracy: 0.7961 - val_loss: 0.4628 - val_accuracy: 0.7779\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4272 - accuracy: 0.7970 - val_loss: 0.4684 - val_accuracy: 0.7713\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4231 - accuracy: 0.8029 - val_loss: 0.4655 - val_accuracy: 0.7779\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4208 - accuracy: 0.8006 - val_loss: 0.4590 - val_accuracy: 0.7769\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.4608 - val_accuracy: 0.7760\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4194 - accuracy: 0.8010 - val_loss: 0.4626 - val_accuracy: 0.7751\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4163 - accuracy: 0.8029 - val_loss: 0.4672 - val_accuracy: 0.7704\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4123 - accuracy: 0.8027 - val_loss: 0.4725 - val_accuracy: 0.7676\n",
      "Epoch 24/40\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4127 - accuracy: 0.8058Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4122 - accuracy: 0.8061 - val_loss: 0.4594 - val_accuracy: 0.7741\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 77.88191437721252\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5904 - accuracy: 0.7016 - val_loss: 0.4977 - val_accuracy: 0.7676\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5040 - accuracy: 0.7524 - val_loss: 0.4640 - val_accuracy: 0.7798\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.7637 - val_loss: 0.4564 - val_accuracy: 0.7863\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4715 - accuracy: 0.7711 - val_loss: 0.4481 - val_accuracy: 0.7854\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4660 - accuracy: 0.7780 - val_loss: 0.4410 - val_accuracy: 0.7873\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4582 - accuracy: 0.7839 - val_loss: 0.4425 - val_accuracy: 0.7873\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4535 - accuracy: 0.7795 - val_loss: 0.4390 - val_accuracy: 0.7882\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.7863 - val_loss: 0.4482 - val_accuracy: 0.7798\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4485 - accuracy: 0.7876 - val_loss: 0.4363 - val_accuracy: 0.7863\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4451 - accuracy: 0.7854 - val_loss: 0.4364 - val_accuracy: 0.7844\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4425 - accuracy: 0.7880 - val_loss: 0.4352 - val_accuracy: 0.7826\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4349 - accuracy: 0.7901 - val_loss: 0.4368 - val_accuracy: 0.7826\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4343 - accuracy: 0.7902 - val_loss: 0.4366 - val_accuracy: 0.7863\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4318 - accuracy: 0.7926 - val_loss: 0.4389 - val_accuracy: 0.7854\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4302 - accuracy: 0.7925 - val_loss: 0.4357 - val_accuracy: 0.7863\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4287 - accuracy: 0.7932 - val_loss: 0.4356 - val_accuracy: 0.7807\n",
      "Epoch 17/40\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.4254 - accuracy: 0.7975Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4264 - accuracy: 0.7964 - val_loss: 0.4379 - val_accuracy: 0.7854\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 78.81911993026733\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5910 - accuracy: 0.6895 - val_loss: 0.5139 - val_accuracy: 0.7495\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.7552 - val_loss: 0.4816 - val_accuracy: 0.7655\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4766 - accuracy: 0.7662 - val_loss: 0.4737 - val_accuracy: 0.7720\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4685 - accuracy: 0.77 - 1s 3ms/step - loss: 0.4685 - accuracy: 0.7737 - val_loss: 0.4712 - val_accuracy: 0.7767\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4618 - accuracy: 0.7779 - val_loss: 0.4644 - val_accuracy: 0.7842\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4549 - accuracy: 0.7817 - val_loss: 0.4635 - val_accuracy: 0.7814\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.7816 - val_loss: 0.4640 - val_accuracy: 0.7777\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4448 - accuracy: 0.7852 - val_loss: 0.4647 - val_accuracy: 0.7824\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4410 - accuracy: 0.7888 - val_loss: 0.4620 - val_accuracy: 0.7795\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4394 - accuracy: 0.7894 - val_loss: 0.4652 - val_accuracy: 0.7786\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4370 - accuracy: 0.7895 - val_loss: 0.4675 - val_accuracy: 0.7749\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4352 - accuracy: 0.7886 - val_loss: 0.4642 - val_accuracy: 0.7833\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4330 - accuracy: 0.7898 - val_loss: 0.4669 - val_accuracy: 0.7805\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4312 - accuracy: 0.7962 - val_loss: 0.4713 - val_accuracy: 0.7777\n",
      "Epoch 15/40\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.4265 - accuracy: 0.7969Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4265 - accuracy: 0.7968 - val_loss: 0.4663 - val_accuracy: 0.7814\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 78.42401266098022\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5953 - accuracy: 0.6984 - val_loss: 0.5236 - val_accuracy: 0.7486\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5026 - val_accuracy: 0.7589\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4818 - accuracy: 0.7634 - val_loss: 0.4831 - val_accuracy: 0.7570\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4716 - accuracy: 0.7690 - val_loss: 0.4799 - val_accuracy: 0.7608\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4630 - accuracy: 0.7782 - val_loss: 0.4767 - val_accuracy: 0.7655\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4574 - accuracy: 0.7818 - val_loss: 0.4744 - val_accuracy: 0.7627\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.4823 - val_accuracy: 0.7683\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4498 - accuracy: 0.7819 - val_loss: 0.4699 - val_accuracy: 0.7598\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4455 - accuracy: 0.7872 - val_loss: 0.4689 - val_accuracy: 0.7598\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4418 - accuracy: 0.7879 - val_loss: 0.4675 - val_accuracy: 0.7692\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.7856 - val_loss: 0.4690 - val_accuracy: 0.7711\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4396 - accuracy: 0.7881 - val_loss: 0.4700 - val_accuracy: 0.7674\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4372 - accuracy: 0.7893 - val_loss: 0.4690 - val_accuracy: 0.7674\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4326 - accuracy: 0.7907 - val_loss: 0.4820 - val_accuracy: 0.7692\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.7929 - val_loss: 0.4705 - val_accuracy: 0.7711\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4307 - accuracy: 0.7920 - val_loss: 0.4708 - val_accuracy: 0.7692\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4270 - accuracy: 0.7952 - val_loss: 0.4702 - val_accuracy: 0.7664\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4263 - accuracy: 0.7978 - val_loss: 0.4727 - val_accuracy: 0.7730\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4232 - accuracy: 0.7974 - val_loss: 0.4730 - val_accuracy: 0.7702\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4216 - accuracy: 0.7994 - val_loss: 0.4749 - val_accuracy: 0.7739\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4178 - accuracy: 0.8038 - val_loss: 0.4726 - val_accuracy: 0.7749\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4156 - accuracy: 0.7999 - val_loss: 0.4799 - val_accuracy: 0.7702\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4117 - accuracy: 0.8016 - val_loss: 0.4735 - val_accuracy: 0.7730\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4129 - accuracy: 0.8037 - val_loss: 0.4754 - val_accuracy: 0.7720\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4084 - accuracy: 0.8028 - val_loss: 0.4788 - val_accuracy: 0.7655\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4066 - accuracy: 0.8087 - val_loss: 0.4784 - val_accuracy: 0.7702\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4075 - accuracy: 0.8060 - val_loss: 0.4821 - val_accuracy: 0.7692\n",
      "Epoch 28/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4037 - accuracy: 0.8066 - val_loss: 0.4891 - val_accuracy: 0.7674\n",
      "Epoch 29/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4032 - accuracy: 0.8092 - val_loss: 0.4972 - val_accuracy: 0.7664\n",
      "Epoch 30/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3999 - accuracy: 0.8102 - val_loss: 0.4910 - val_accuracy: 0.7617\n",
      "Epoch 31/40\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.3971 - accuracy: 0.8114Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3982 - accuracy: 0.8108 - val_loss: 0.4864 - val_accuracy: 0.7617\n",
      "Epoch 00031: early stopping\n",
      "Test Accuracy: 77.48593091964722\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5988 - accuracy: 0.6859 - val_loss: 0.5018 - val_accuracy: 0.7767\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5063 - accuracy: 0.7509 - val_loss: 0.4681 - val_accuracy: 0.7805\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7659 - val_loss: 0.4666 - val_accuracy: 0.7842\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.7726 - val_loss: 0.4567 - val_accuracy: 0.7805\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7745 - val_loss: 0.4588 - val_accuracy: 0.7908\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.7832 - val_loss: 0.4534 - val_accuracy: 0.7805\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.7841 - val_loss: 0.4555 - val_accuracy: 0.7767\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.7799 - val_loss: 0.4564 - val_accuracy: 0.7749\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.7857 - val_loss: 0.4542 - val_accuracy: 0.7805\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4444 - accuracy: 0.7909 - val_loss: 0.4538 - val_accuracy: 0.7824\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.7895 - val_loss: 0.4542 - val_accuracy: 0.7805\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4383 - accuracy: 0.7906 - val_loss: 0.4559 - val_accuracy: 0.7758\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.7892 - val_loss: 0.4548 - val_accuracy: 0.7824\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4352 - accuracy: 0.7923 - val_loss: 0.4563 - val_accuracy: 0.7749\n",
      "Epoch 15/40\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4311 - accuracy: 0.7929Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4304 - accuracy: 0.7929 - val_loss: 0.4544 - val_accuracy: 0.7758\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 79.0806770324707\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5941 - accuracy: 0.6942 - val_loss: 0.5187 - val_accuracy: 0.7505\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4992 - accuracy: 0.7578 - val_loss: 0.5003 - val_accuracy: 0.7580\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4753 - accuracy: 0.7681 - val_loss: 0.4795 - val_accuracy: 0.7730\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4692 - accuracy: 0.7738 - val_loss: 0.4753 - val_accuracy: 0.7674\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.7805 - val_loss: 0.4732 - val_accuracy: 0.7720\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4552 - accuracy: 0.7824 - val_loss: 0.4743 - val_accuracy: 0.7692\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.7801 - val_loss: 0.4704 - val_accuracy: 0.7711\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.7843 - val_loss: 0.4722 - val_accuracy: 0.7711\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.7886 - val_loss: 0.4801 - val_accuracy: 0.7674\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4401 - accuracy: 0.7889 - val_loss: 0.4714 - val_accuracy: 0.7702\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4402 - accuracy: 0.7930 - val_loss: 0.4786 - val_accuracy: 0.7664\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4342 - accuracy: 0.7928 - val_loss: 0.4825 - val_accuracy: 0.7598\n",
      "Epoch 13/40\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.7905Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4348 - accuracy: 0.7912 - val_loss: 0.4674 - val_accuracy: 0.7730\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 77.29831337928772\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5951 - accuracy: 0.6907 - val_loss: 0.5135 - val_accuracy: 0.7533\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.7546 - val_loss: 0.4812 - val_accuracy: 0.7561\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4798 - accuracy: 0.7680 - val_loss: 0.4724 - val_accuracy: 0.7674\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4699 - accuracy: 0.7777 - val_loss: 0.4670 - val_accuracy: 0.7702\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.7798 - val_loss: 0.4624 - val_accuracy: 0.7795\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4545 - accuracy: 0.7807 - val_loss: 0.4612 - val_accuracy: 0.7749\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.7815 - val_loss: 0.4597 - val_accuracy: 0.7720\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.79 - 1s 2ms/step - loss: 0.4472 - accuracy: 0.7911 - val_loss: 0.4589 - val_accuracy: 0.7767\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.7877 - val_loss: 0.4612 - val_accuracy: 0.7739\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.7888 - val_loss: 0.4569 - val_accuracy: 0.7739\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.7902 - val_loss: 0.4565 - val_accuracy: 0.7805\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4558 - val_accuracy: 0.7758\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.7887 - val_loss: 0.4559 - val_accuracy: 0.7777\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4325 - accuracy: 0.7935 - val_loss: 0.4604 - val_accuracy: 0.7777\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4308 - accuracy: 0.7968 - val_loss: 0.4560 - val_accuracy: 0.7777\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4303 - accuracy: 0.7964 - val_loss: 0.4569 - val_accuracy: 0.7861\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4254 - accuracy: 0.7966 - val_loss: 0.4593 - val_accuracy: 0.7692\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4246 - accuracy: 0.7986 - val_loss: 0.4578 - val_accuracy: 0.7777\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4232 - accuracy: 0.8010 - val_loss: 0.4619 - val_accuracy: 0.7749\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4231 - accuracy: 0.7992 - val_loss: 0.4647 - val_accuracy: 0.7720\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4220 - accuracy: 0.8025 - val_loss: 0.4583 - val_accuracy: 0.7833\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4188 - accuracy: 0.8039 - val_loss: 0.4573 - val_accuracy: 0.7833\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4145 - accuracy: 0.8047 - val_loss: 0.4626 - val_accuracy: 0.7805\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.8060 - val_loss: 0.4614 - val_accuracy: 0.7880\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4139 - accuracy: 0.8102 - val_loss: 0.4724 - val_accuracy: 0.7720\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8084 - val_loss: 0.4617 - val_accuracy: 0.7777\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4095 - accuracy: 0.8103 - val_loss: 0.4588 - val_accuracy: 0.7833\n",
      "Epoch 28/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4065 - accuracy: 0.8151 - val_loss: 0.4654 - val_accuracy: 0.7833\n",
      "Epoch 29/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4020 - accuracy: 0.8164 - val_loss: 0.4639 - val_accuracy: 0.7852\n",
      "Epoch 30/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8180 - val_loss: 0.4678 - val_accuracy: 0.7833\n",
      "Epoch 31/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4013 - accuracy: 0.8168 - val_loss: 0.4660 - val_accuracy: 0.7824\n",
      "Epoch 32/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3948 - accuracy: 0.8176 - val_loss: 0.4715 - val_accuracy: 0.7852\n",
      "Epoch 33/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3953 - accuracy: 0.8158 - val_loss: 0.4692 - val_accuracy: 0.7842\n",
      "Epoch 34/40\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.3935 - accuracy: 0.8190Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3935 - accuracy: 0.8188 - val_loss: 0.4719 - val_accuracy: 0.7739\n",
      "Epoch 00034: early stopping\n",
      "Test Accuracy: 78.79924774169922\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.6906 - val_loss: 0.5171 - val_accuracy: 0.7523\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7546 - val_loss: 0.4866 - val_accuracy: 0.7692\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.7690 - val_loss: 0.4824 - val_accuracy: 0.7645\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4701 - accuracy: 0.7733 - val_loss: 0.4746 - val_accuracy: 0.7767\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.7786 - val_loss: 0.4769 - val_accuracy: 0.7739\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.7823 - val_loss: 0.4733 - val_accuracy: 0.7711\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4499 - accuracy: 0.7854 - val_loss: 0.4697 - val_accuracy: 0.7777\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4470 - accuracy: 0.7805 - val_loss: 0.4679 - val_accuracy: 0.7758\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4448 - accuracy: 0.7855 - val_loss: 0.4753 - val_accuracy: 0.7730\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.7860 - val_loss: 0.4655 - val_accuracy: 0.7758\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4385 - accuracy: 0.7903 - val_loss: 0.4657 - val_accuracy: 0.7739\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.7890 - val_loss: 0.4662 - val_accuracy: 0.7852\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.7883 - val_loss: 0.4651 - val_accuracy: 0.7795\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4303 - accuracy: 0.7938 - val_loss: 0.4652 - val_accuracy: 0.7786\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4296 - accuracy: 0.7921 - val_loss: 0.4665 - val_accuracy: 0.7711\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4281 - accuracy: 0.7904 - val_loss: 0.4743 - val_accuracy: 0.7730\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4258 - accuracy: 0.7952 - val_loss: 0.4646 - val_accuracy: 0.7758\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4223 - accuracy: 0.7971 - val_loss: 0.4661 - val_accuracy: 0.7871\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4237 - accuracy: 0.8009 - val_loss: 0.4658 - val_accuracy: 0.7786\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.7993 - val_loss: 0.4676 - val_accuracy: 0.7767\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4187 - accuracy: 0.7995 - val_loss: 0.4751 - val_accuracy: 0.7692\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4185 - accuracy: 0.8033 - val_loss: 0.4642 - val_accuracy: 0.7833\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4133 - accuracy: 0.8061 - val_loss: 0.4781 - val_accuracy: 0.7692\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8044 - val_loss: 0.4670 - val_accuracy: 0.7833\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4107 - accuracy: 0.8052 - val_loss: 0.4671 - val_accuracy: 0.7824\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4079 - accuracy: 0.8047 - val_loss: 0.4714 - val_accuracy: 0.7871\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4076 - accuracy: 0.8042 - val_loss: 0.4681 - val_accuracy: 0.7833\n",
      "Epoch 28/40\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.4082 - accuracy: 0.8086Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4080 - accuracy: 0.8080 - val_loss: 0.4696 - val_accuracy: 0.7795\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 78.70544195175171\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5895 - accuracy: 0.6949 - val_loss: 0.5220 - val_accuracy: 0.7355\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.7568 - val_loss: 0.4963 - val_accuracy: 0.7430\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4786 - accuracy: 0.7706 - val_loss: 0.4883 - val_accuracy: 0.7505\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.7755 - val_loss: 0.4827 - val_accuracy: 0.7570\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.7744 - val_loss: 0.4781 - val_accuracy: 0.7570\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4568 - accuracy: 0.7804 - val_loss: 0.4787 - val_accuracy: 0.7608\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.7817 - val_loss: 0.4775 - val_accuracy: 0.7617\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.7825 - val_loss: 0.4798 - val_accuracy: 0.7589\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4453 - accuracy: 0.7849 - val_loss: 0.4774 - val_accuracy: 0.7598\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.7889 - val_loss: 0.4832 - val_accuracy: 0.7589\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4394 - accuracy: 0.7892 - val_loss: 0.4772 - val_accuracy: 0.7655\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4364 - accuracy: 0.7942 - val_loss: 0.4756 - val_accuracy: 0.7692\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4347 - accuracy: 0.7921 - val_loss: 0.4749 - val_accuracy: 0.7655\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.7914 - val_loss: 0.4788 - val_accuracy: 0.7617\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4306 - accuracy: 0.7945 - val_loss: 0.4749 - val_accuracy: 0.7720\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4300 - accuracy: 0.7946 - val_loss: 0.4751 - val_accuracy: 0.7655\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4252 - accuracy: 0.7985 - val_loss: 0.4758 - val_accuracy: 0.7702\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4232 - accuracy: 0.7991 - val_loss: 0.4766 - val_accuracy: 0.7730\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4209 - accuracy: 0.8030 - val_loss: 0.4772 - val_accuracy: 0.7674\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4202 - accuracy: 0.7996 - val_loss: 0.4743 - val_accuracy: 0.7683\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.4794 - val_accuracy: 0.7749\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4179 - accuracy: 0.8027 - val_loss: 0.4790 - val_accuracy: 0.7730\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4126 - accuracy: 0.8059 - val_loss: 0.4779 - val_accuracy: 0.7730\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4094 - accuracy: 0.8074 - val_loss: 0.4801 - val_accuracy: 0.7702\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4112 - accuracy: 0.8078 - val_loss: 0.4803 - val_accuracy: 0.7711\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4081 - accuracy: 0.8087 - val_loss: 0.4782 - val_accuracy: 0.7777\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4065 - accuracy: 0.8055 - val_loss: 0.4819 - val_accuracy: 0.7795\n",
      "Epoch 28/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4057 - accuracy: 0.8094 - val_loss: 0.4756 - val_accuracy: 0.7767\n",
      "Epoch 29/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8153 - val_loss: 0.4838 - val_accuracy: 0.7777\n",
      "Epoch 30/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4001 - accuracy: 0.8129 - val_loss: 0.4795 - val_accuracy: 0.7767\n",
      "Epoch 31/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4012 - accuracy: 0.8147 - val_loss: 0.4820 - val_accuracy: 0.7711\n",
      "Epoch 32/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3996 - accuracy: 0.8122 - val_loss: 0.4810 - val_accuracy: 0.7711\n",
      "Epoch 33/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3932 - accuracy: 0.8201 - val_loss: 0.4875 - val_accuracy: 0.7739\n",
      "Epoch 34/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3925 - accuracy: 0.8163 - val_loss: 0.4822 - val_accuracy: 0.7805\n",
      "Epoch 35/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3896 - accuracy: 0.8199 - val_loss: 0.4813 - val_accuracy: 0.7739\n",
      "Epoch 36/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3917 - accuracy: 0.8227 - val_loss: 0.4829 - val_accuracy: 0.7730\n",
      "Epoch 37/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3873 - accuracy: 0.8222 - val_loss: 0.4859 - val_accuracy: 0.7702\n",
      "Epoch 38/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3854 - accuracy: 0.8222 - val_loss: 0.4865 - val_accuracy: 0.7730\n",
      "Epoch 39/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3806 - accuracy: 0.8283 - val_loss: 0.4820 - val_accuracy: 0.7880\n",
      "Epoch 40/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3813 - accuracy: 0.8241 - val_loss: 0.4861 - val_accuracy: 0.7824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 78.23639512062073\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.6881 - val_loss: 0.5348 - val_accuracy: 0.7223\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4982 - accuracy: 0.7586 - val_loss: 0.5116 - val_accuracy: 0.7373\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4790 - accuracy: 0.7698 - val_loss: 0.5010 - val_accuracy: 0.7420\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.7779 - val_loss: 0.4936 - val_accuracy: 0.7514\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4613 - accuracy: 0.7789 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.7789 - val_loss: 0.4887 - val_accuracy: 0.7589\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.7839 - val_loss: 0.4871 - val_accuracy: 0.7608\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.7851 - val_loss: 0.4860 - val_accuracy: 0.7580\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4462 - accuracy: 0.7868 - val_loss: 0.4839 - val_accuracy: 0.7636\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4889 - val_accuracy: 0.7552\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.7917 - val_loss: 0.4842 - val_accuracy: 0.7589\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4357 - accuracy: 0.7905 - val_loss: 0.4873 - val_accuracy: 0.7561\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.7932 - val_loss: 0.4890 - val_accuracy: 0.7561\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4342 - accuracy: 0.7939 - val_loss: 0.4787 - val_accuracy: 0.7598\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.7926 - val_loss: 0.4796 - val_accuracy: 0.7580\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4281 - accuracy: 0.7950 - val_loss: 0.4828 - val_accuracy: 0.7542\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4249 - accuracy: 0.7971 - val_loss: 0.4808 - val_accuracy: 0.7589\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4214 - accuracy: 0.8024 - val_loss: 0.4849 - val_accuracy: 0.7514\n",
      "Epoch 19/40\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.4224 - accuracy: 0.8009Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4222 - accuracy: 0.8018 - val_loss: 0.4796 - val_accuracy: 0.7514\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 76.36022567749023\n",
      "\n",
      "\n",
      "        acc1      acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
      "0  77.881914  78.81912  78.424013  77.485931  79.080677  77.298313  78.799248   \n",
      "\n",
      "        acc8       acc9      acc10        AVG  \n",
      "0  78.705442  78.236395  76.360226  78.109128  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Obtain the word to index\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record = record.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.881914</td>\n",
       "      <td>78.81912</td>\n",
       "      <td>78.424013</td>\n",
       "      <td>77.485931</td>\n",
       "      <td>79.080677</td>\n",
       "      <td>77.298313</td>\n",
       "      <td>78.799248</td>\n",
       "      <td>78.705442</td>\n",
       "      <td>78.236395</td>\n",
       "      <td>76.360226</td>\n",
       "      <td>78.109128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1      acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
       "0  77.881914  78.81912  78.424013  77.485931  79.080677  77.298313  78.799248   \n",
       "\n",
       "        acc8       acc9      acc10        AVG  \n",
       "0  78.705442  78.236395  76.360226  78.109128  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record\n",
    "report = report.to_excel('Emb_MLP_MR.xlsx', sheet_name='model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_2(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 30,201\n",
      "Trainable params: 30,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = define_model_2(300)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5790 - accuracy: 0.7084 - val_loss: 0.5096 - val_accuracy: 0.7488\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4885 - accuracy: 0.7676 - val_loss: 0.4828 - val_accuracy: 0.7601\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4726 - accuracy: 0.7720 - val_loss: 0.4756 - val_accuracy: 0.7704\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4614 - accuracy: 0.7800 - val_loss: 0.4731 - val_accuracy: 0.7751\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4552 - accuracy: 0.7806 - val_loss: 0.4709 - val_accuracy: 0.7732\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.7855 - val_loss: 0.4677 - val_accuracy: 0.7741\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4684 - val_accuracy: 0.7732\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4420 - accuracy: 0.7904 - val_loss: 0.4648 - val_accuracy: 0.7741\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.4689 - val_accuracy: 0.7713\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4320 - accuracy: 0.7923 - val_loss: 0.4631 - val_accuracy: 0.7732\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4321 - accuracy: 0.7929 - val_loss: 0.4634 - val_accuracy: 0.7694\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4278 - accuracy: 0.7976 - val_loss: 0.4641 - val_accuracy: 0.7751\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4237 - accuracy: 0.7975 - val_loss: 0.4661 - val_accuracy: 0.7685\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4223 - accuracy: 0.7982 - val_loss: 0.4599 - val_accuracy: 0.7798\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4182 - accuracy: 0.8010 - val_loss: 0.4616 - val_accuracy: 0.7704\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4138 - accuracy: 0.8040 - val_loss: 0.4622 - val_accuracy: 0.7741\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4139 - accuracy: 0.8051 - val_loss: 0.4674 - val_accuracy: 0.7648\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4090 - accuracy: 0.8057 - val_loss: 0.4631 - val_accuracy: 0.7713\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4057 - accuracy: 0.8089 - val_loss: 0.4594 - val_accuracy: 0.7769\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4044 - accuracy: 0.8063 - val_loss: 0.4612 - val_accuracy: 0.7751\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3995 - accuracy: 0.8139 - val_loss: 0.4590 - val_accuracy: 0.7741\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3980 - accuracy: 0.8142 - val_loss: 0.4662 - val_accuracy: 0.7732\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8153 - val_loss: 0.4591 - val_accuracy: 0.7798\n",
      "Epoch 24/40\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.3939 - accuracy: 0.8185Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3938 - accuracy: 0.8180 - val_loss: 0.4677 - val_accuracy: 0.7648\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 77.97563076019287\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5728 - accuracy: 0.7108 - val_loss: 0.5147 - val_accuracy: 0.7460\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4868 - accuracy: 0.7629 - val_loss: 0.4975 - val_accuracy: 0.7507\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.7687 - val_loss: 0.4830 - val_accuracy: 0.7676\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4569 - accuracy: 0.7779 - val_loss: 0.4869 - val_accuracy: 0.7629\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4511 - accuracy: 0.7805 - val_loss: 0.4785 - val_accuracy: 0.7657\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.7837 - val_loss: 0.4793 - val_accuracy: 0.7619\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.7831 - val_loss: 0.4799 - val_accuracy: 0.7713\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4381 - accuracy: 0.7866 - val_loss: 0.4812 - val_accuracy: 0.7648\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4338 - accuracy: 0.7905 - val_loss: 0.4813 - val_accuracy: 0.7601\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4319 - accuracy: 0.7919 - val_loss: 0.4757 - val_accuracy: 0.7554\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4253 - accuracy: 0.7934 - val_loss: 0.4772 - val_accuracy: 0.7723\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4795 - val_accuracy: 0.7685\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4192 - accuracy: 0.7965 - val_loss: 0.4749 - val_accuracy: 0.7638\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4163 - accuracy: 0.7995 - val_loss: 0.4800 - val_accuracy: 0.7713\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8043 - val_loss: 0.4835 - val_accuracy: 0.7704\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4113 - accuracy: 0.8039 - val_loss: 0.4819 - val_accuracy: 0.7685\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4058 - accuracy: 0.8097 - val_loss: 0.4776 - val_accuracy: 0.7676\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4062 - accuracy: 0.8055 - val_loss: 0.4851 - val_accuracy: 0.7648\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8117 - val_loss: 0.4863 - val_accuracy: 0.7648\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3983 - accuracy: 0.8101 - val_loss: 0.4771 - val_accuracy: 0.7704\n",
      "Epoch 21/40\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.3950 - accuracy: 0.8158Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8147 - val_loss: 0.4845 - val_accuracy: 0.7638\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 77.22586989402771\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5735 - accuracy: 0.7074 - val_loss: 0.5080 - val_accuracy: 0.7514\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4906 - accuracy: 0.7582 - val_loss: 0.4811 - val_accuracy: 0.7608\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.7739 - val_loss: 0.4718 - val_accuracy: 0.7570\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4622 - accuracy: 0.7793 - val_loss: 0.4669 - val_accuracy: 0.7645\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7816 - val_loss: 0.4660 - val_accuracy: 0.7683\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4495 - accuracy: 0.7867 - val_loss: 0.4621 - val_accuracy: 0.7655\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4467 - accuracy: 0.7877 - val_loss: 0.4602 - val_accuracy: 0.7655\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.7868 - val_loss: 0.4559 - val_accuracy: 0.7692\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.7891 - val_loss: 0.4546 - val_accuracy: 0.7664\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.7896 - val_loss: 0.4515 - val_accuracy: 0.7730\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4315 - accuracy: 0.7955 - val_loss: 0.4539 - val_accuracy: 0.7692\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4275 - accuracy: 0.7942 - val_loss: 0.4539 - val_accuracy: 0.7664\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4269 - accuracy: 0.7949 - val_loss: 0.4546 - val_accuracy: 0.7636\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4220 - accuracy: 0.8019 - val_loss: 0.4585 - val_accuracy: 0.7598\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4206 - accuracy: 0.8010 - val_loss: 0.4483 - val_accuracy: 0.7795\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4164 - accuracy: 0.8047 - val_loss: 0.4536 - val_accuracy: 0.7692\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4126 - accuracy: 0.8041 - val_loss: 0.4492 - val_accuracy: 0.7720\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4101 - accuracy: 0.8040 - val_loss: 0.4520 - val_accuracy: 0.7720\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4038 - accuracy: 0.8099 - val_loss: 0.4489 - val_accuracy: 0.7758\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8117 - val_loss: 0.4468 - val_accuracy: 0.7767\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8127 - val_loss: 0.4466 - val_accuracy: 0.7767\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8153 - val_loss: 0.4541 - val_accuracy: 0.7702\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3942 - accuracy: 0.8164 - val_loss: 0.4478 - val_accuracy: 0.7692\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3913 - accuracy: 0.8163 - val_loss: 0.4488 - val_accuracy: 0.7674\n",
      "Epoch 25/40\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.3859 - accuracy: 0.8191 ETA: 0s - loss: 0.3882 - accuracy: 0.Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3877 - accuracy: 0.8176 - val_loss: 0.4504 - val_accuracy: 0.7739\n",
      "Epoch 00025: early stopping\n",
      "Test Accuracy: 77.95497179031372\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5755 - accuracy: 0.7080 - val_loss: 0.5074 - val_accuracy: 0.7486\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.7570 - val_loss: 0.4869 - val_accuracy: 0.7617\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4745 - accuracy: 0.7699 - val_loss: 0.4713 - val_accuracy: 0.7655\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.7718 - val_loss: 0.4712 - val_accuracy: 0.7702\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.7831 - val_loss: 0.4642 - val_accuracy: 0.7730\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.7844 - val_loss: 0.4626 - val_accuracy: 0.7767\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.7842 - val_loss: 0.4628 - val_accuracy: 0.7739\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.7869 - val_loss: 0.4675 - val_accuracy: 0.7627\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.7872 - val_loss: 0.4648 - val_accuracy: 0.7617\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4350 - accuracy: 0.7918 - val_loss: 0.4578 - val_accuracy: 0.7739\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4318 - accuracy: 0.7911 - val_loss: 0.4643 - val_accuracy: 0.7739\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4274 - accuracy: 0.7964 - val_loss: 0.4566 - val_accuracy: 0.7758\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4254 - accuracy: 0.7927 - val_loss: 0.4555 - val_accuracy: 0.7711\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.7971 - val_loss: 0.4539 - val_accuracy: 0.7692\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4178 - accuracy: 0.7997 - val_loss: 0.4550 - val_accuracy: 0.7758\n",
      "Epoch 16/40\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.4146 - accuracy: 0.8023Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4149 - accuracy: 0.8024 - val_loss: 0.4529 - val_accuracy: 0.7702\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 77.67354846000671\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5705 - accuracy: 0.7127 - val_loss: 0.4994 - val_accuracy: 0.7617\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4893 - accuracy: 0.7623 - val_loss: 0.4832 - val_accuracy: 0.7674\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7695 - val_loss: 0.4855 - val_accuracy: 0.7580\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4590 - accuracy: 0.7784 - val_loss: 0.4788 - val_accuracy: 0.7720\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.7838 - val_loss: 0.4775 - val_accuracy: 0.7608\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.7835 - val_loss: 0.4746 - val_accuracy: 0.7711\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4444 - accuracy: 0.7869 - val_loss: 0.4759 - val_accuracy: 0.7655\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4383 - accuracy: 0.7911 - val_loss: 0.4734 - val_accuracy: 0.7692\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.7891 - val_loss: 0.4758 - val_accuracy: 0.7692\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4345 - accuracy: 0.7912 - val_loss: 0.4747 - val_accuracy: 0.7636\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4286 - accuracy: 0.7936 - val_loss: 0.4759 - val_accuracy: 0.7720\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4276 - accuracy: 0.7961 - val_loss: 0.4751 - val_accuracy: 0.7692\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4239 - accuracy: 0.7961 - val_loss: 0.4820 - val_accuracy: 0.7702\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4198 - accuracy: 0.8000 - val_loss: 0.4783 - val_accuracy: 0.7739\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4183 - accuracy: 0.8005 - val_loss: 0.4770 - val_accuracy: 0.7777\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4131 - accuracy: 0.8004 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8040 - val_loss: 0.4787 - val_accuracy: 0.7758\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4074 - accuracy: 0.8060 - val_loss: 0.4806 - val_accuracy: 0.7711\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4044 - accuracy: 0.8055 - val_loss: 0.4802 - val_accuracy: 0.7749\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8087 - val_loss: 0.4794 - val_accuracy: 0.7795\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8098 - val_loss: 0.4802 - val_accuracy: 0.7720\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3947 - accuracy: 0.8154 - val_loss: 0.4823 - val_accuracy: 0.7805\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3925 - accuracy: 0.8149 - val_loss: 0.4886 - val_accuracy: 0.7805\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3893 - accuracy: 0.8158 - val_loss: 0.4852 - val_accuracy: 0.7795\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8215 - val_loss: 0.4871 - val_accuracy: 0.7777\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3830 - accuracy: 0.8203 - val_loss: 0.4891 - val_accuracy: 0.7711\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3792 - accuracy: 0.8234 - val_loss: 0.4890 - val_accuracy: 0.7758\n",
      "Epoch 28/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3747 - accuracy: 0.8245 - val_loss: 0.4917 - val_accuracy: 0.7824\n",
      "Epoch 29/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3737 - accuracy: 0.8261 - val_loss: 0.4904 - val_accuracy: 0.7758\n",
      "Epoch 30/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3673 - accuracy: 0.8320 - val_loss: 0.4952 - val_accuracy: 0.7739\n",
      "Epoch 31/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3651 - accuracy: 0.8311 - val_loss: 0.4910 - val_accuracy: 0.7814\n",
      "Epoch 32/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.8318 - val_loss: 0.4908 - val_accuracy: 0.7720\n",
      "Epoch 33/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3579 - accuracy: 0.8385 - val_loss: 0.4964 - val_accuracy: 0.7758\n",
      "Epoch 34/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3580 - accuracy: 0.8341 - val_loss: 0.4904 - val_accuracy: 0.7749\n",
      "Epoch 35/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8382 - val_loss: 0.5004 - val_accuracy: 0.7692\n",
      "Epoch 36/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8404 - val_loss: 0.4997 - val_accuracy: 0.7702\n",
      "Epoch 37/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8459 - val_loss: 0.5083 - val_accuracy: 0.7730\n",
      "Epoch 38/40\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.3394 - accuracy: 0.8488Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3398 - accuracy: 0.8487 - val_loss: 0.5029 - val_accuracy: 0.7683\n",
      "Epoch 00038: early stopping\n",
      "Test Accuracy: 78.23639512062073\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5747 - accuracy: 0.7075 - val_loss: 0.4822 - val_accuracy: 0.7730\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4912 - accuracy: 0.7619 - val_loss: 0.4603 - val_accuracy: 0.7908\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.7717 - val_loss: 0.4554 - val_accuracy: 0.7824\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.7752 - val_loss: 0.4664 - val_accuracy: 0.7758\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4555 - accuracy: 0.7801 - val_loss: 0.4691 - val_accuracy: 0.7777\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4535 - accuracy: 0.7825 - val_loss: 0.4510 - val_accuracy: 0.7833\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.7850 - val_loss: 0.4480 - val_accuracy: 0.7805\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4409 - accuracy: 0.7875 - val_loss: 0.4485 - val_accuracy: 0.7842\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4404 - accuracy: 0.7912 - val_loss: 0.4488 - val_accuracy: 0.7814\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4361 - accuracy: 0.7895 - val_loss: 0.4522 - val_accuracy: 0.7861\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.7935 - val_loss: 0.4479 - val_accuracy: 0.7739\n",
      "Epoch 12/40\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4305 - accuracy: 0.7927Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4300 - accuracy: 0.7937 - val_loss: 0.4455 - val_accuracy: 0.7833\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.0806770324707\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5723 - accuracy: 0.7030 - val_loss: 0.4963 - val_accuracy: 0.7589\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4897 - accuracy: 0.7625 - val_loss: 0.4710 - val_accuracy: 0.7627\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4741 - accuracy: 0.7701 - val_loss: 0.4665 - val_accuracy: 0.7720\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.7780 - val_loss: 0.4662 - val_accuracy: 0.7749\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.7787 - val_loss: 0.4613 - val_accuracy: 0.7636\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4527 - accuracy: 0.7857 - val_loss: 0.4641 - val_accuracy: 0.7758\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.7900 - val_loss: 0.4538 - val_accuracy: 0.7786\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4430 - accuracy: 0.7880 - val_loss: 0.4554 - val_accuracy: 0.7664\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.7900 - val_loss: 0.4616 - val_accuracy: 0.7786\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.7938 - val_loss: 0.4570 - val_accuracy: 0.7786\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4352 - accuracy: 0.7912 - val_loss: 0.4546 - val_accuracy: 0.7767\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4278 - accuracy: 0.7926 - val_loss: 0.4540 - val_accuracy: 0.7749\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4270 - accuracy: 0.7941 - val_loss: 0.4572 - val_accuracy: 0.7730\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4524 - val_accuracy: 0.7833\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8008 - val_loss: 0.4608 - val_accuracy: 0.7777\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4180 - accuracy: 0.8027 - val_loss: 0.4529 - val_accuracy: 0.7805\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4152 - accuracy: 0.8046 - val_loss: 0.4519 - val_accuracy: 0.7833\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4127 - accuracy: 0.8053 - val_loss: 0.4510 - val_accuracy: 0.7767\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4093 - accuracy: 0.8078 - val_loss: 0.4518 - val_accuracy: 0.7861\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4091 - accuracy: 0.8062 - val_loss: 0.4578 - val_accuracy: 0.7833\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4030 - accuracy: 0.8100 - val_loss: 0.4538 - val_accuracy: 0.7824\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4012 - accuracy: 0.8153 - val_loss: 0.4536 - val_accuracy: 0.7880\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3988 - accuracy: 0.8169 - val_loss: 0.4559 - val_accuracy: 0.7824\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3927 - accuracy: 0.8161 - val_loss: 0.4632 - val_accuracy: 0.7814\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3915 - accuracy: 0.8158 - val_loss: 0.4618 - val_accuracy: 0.7795\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3871 - accuracy: 0.8220 - val_loss: 0.4567 - val_accuracy: 0.7824\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3873 - accuracy: 0.8234 - val_loss: 0.4606 - val_accuracy: 0.7767\n",
      "Epoch 28/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3810 - accuracy: 0.8251 - val_loss: 0.4656 - val_accuracy: 0.7814\n",
      "Epoch 29/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3809 - accuracy: 0.8262 - val_loss: 0.4642 - val_accuracy: 0.7777\n",
      "Epoch 30/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3742 - accuracy: 0.8278 - val_loss: 0.4637 - val_accuracy: 0.7739\n",
      "Epoch 31/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3715 - accuracy: 0.8334 - val_loss: 0.4675 - val_accuracy: 0.7814\n",
      "Epoch 32/40\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.3694 - accuracy: 0.8354Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8348 - val_loss: 0.4649 - val_accuracy: 0.7795\n",
      "Epoch 00032: early stopping\n",
      "Test Accuracy: 78.79924774169922\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5737 - accuracy: 0.7090 - val_loss: 0.5124 - val_accuracy: 0.7420\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.7649 - val_loss: 0.4954 - val_accuracy: 0.7589\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4848 - val_accuracy: 0.7636\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.7768 - val_loss: 0.4820 - val_accuracy: 0.7730\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.7832 - val_loss: 0.4815 - val_accuracy: 0.7720\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4471 - accuracy: 0.7825 - val_loss: 0.4795 - val_accuracy: 0.7730\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.7855 - val_loss: 0.4805 - val_accuracy: 0.7730\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4382 - accuracy: 0.7904 - val_loss: 0.4794 - val_accuracy: 0.7749\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.7893 - val_loss: 0.4807 - val_accuracy: 0.7795\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4305 - accuracy: 0.7929 - val_loss: 0.4886 - val_accuracy: 0.7664\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4264 - accuracy: 0.7949 - val_loss: 0.4805 - val_accuracy: 0.7720\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4249 - accuracy: 0.7976 - val_loss: 0.4846 - val_accuracy: 0.7655\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.7978 - val_loss: 0.4806 - val_accuracy: 0.7824\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4207 - accuracy: 0.7972 - val_loss: 0.4821 - val_accuracy: 0.7730\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4153 - accuracy: 0.7995 - val_loss: 0.4872 - val_accuracy: 0.7767\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4149 - accuracy: 0.8051 - val_loss: 0.4804 - val_accuracy: 0.7795\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4101 - accuracy: 0.8078 - val_loss: 0.4850 - val_accuracy: 0.7786\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.80 - 1s 2ms/step - loss: 0.4078 - accuracy: 0.8084 - val_loss: 0.4812 - val_accuracy: 0.7795\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4034 - accuracy: 0.8110 - val_loss: 0.4899 - val_accuracy: 0.7767\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.4867 - val_accuracy: 0.7692\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3976 - accuracy: 0.8135 - val_loss: 0.4926 - val_accuracy: 0.7749\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3927 - accuracy: 0.8169 - val_loss: 0.4840 - val_accuracy: 0.7749\n",
      "Epoch 23/40\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.3917 - accuracy: 0.8166Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3923 - accuracy: 0.8165 - val_loss: 0.4958 - val_accuracy: 0.7720\n",
      "Epoch 00023: early stopping\n",
      "Test Accuracy: 78.23639512062073\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5736 - accuracy: 0.7060 - val_loss: 0.4975 - val_accuracy: 0.7561\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.7647 - val_loss: 0.4815 - val_accuracy: 0.7636\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.7737 - val_loss: 0.4737 - val_accuracy: 0.7702\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.7764 - val_loss: 0.4724 - val_accuracy: 0.7749\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4543 - accuracy: 0.7815 - val_loss: 0.4699 - val_accuracy: 0.7758\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.7827 - val_loss: 0.4756 - val_accuracy: 0.7702\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.7878 - val_loss: 0.4742 - val_accuracy: 0.7627\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.7891 - val_loss: 0.4697 - val_accuracy: 0.7702\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4401 - accuracy: 0.7881 - val_loss: 0.4721 - val_accuracy: 0.7608\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.7873 - val_loss: 0.4748 - val_accuracy: 0.7608\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.7914 - val_loss: 0.4734 - val_accuracy: 0.7767\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4296 - accuracy: 0.7951 - val_loss: 0.4793 - val_accuracy: 0.7589\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4254 - accuracy: 0.7967 - val_loss: 0.4735 - val_accuracy: 0.7692\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4240 - accuracy: 0.7962 - val_loss: 0.4730 - val_accuracy: 0.7636\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4217 - accuracy: 0.8006 - val_loss: 0.4757 - val_accuracy: 0.7664\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4197 - accuracy: 0.7980 - val_loss: 0.4746 - val_accuracy: 0.7683\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4143 - accuracy: 0.8029 - val_loss: 0.4753 - val_accuracy: 0.7683\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8043 - val_loss: 0.4837 - val_accuracy: 0.7589\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4073 - accuracy: 0.8081 - val_loss: 0.4767 - val_accuracy: 0.7683\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4075 - accuracy: 0.8088 - val_loss: 0.4898 - val_accuracy: 0.7664\n",
      "Epoch 21/40\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.4024 - accuracy: 0.8107Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4039 - accuracy: 0.8099 - val_loss: 0.4825 - val_accuracy: 0.7711\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 77.67354846000671\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5657 - accuracy: 0.7184 - val_loss: 0.5045 - val_accuracy: 0.7505\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.7624 - val_loss: 0.4866 - val_accuracy: 0.7589\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4694 - accuracy: 0.7743 - val_loss: 0.4799 - val_accuracy: 0.7505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4583 - accuracy: 0.7815 - val_loss: 0.4803 - val_accuracy: 0.7580\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4546 - accuracy: 0.7836 - val_loss: 0.4756 - val_accuracy: 0.7617\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4479 - accuracy: 0.7838 - val_loss: 0.4716 - val_accuracy: 0.7627\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.7870 - val_loss: 0.4713 - val_accuracy: 0.7636\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4357 - accuracy: 0.7912 - val_loss: 0.4731 - val_accuracy: 0.7617\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.7910 - val_loss: 0.4738 - val_accuracy: 0.7608\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4358 - accuracy: 0.7892 - val_loss: 0.4753 - val_accuracy: 0.7570\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4314 - accuracy: 0.7895 - val_loss: 0.4777 - val_accuracy: 0.7636\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.4722 - val_accuracy: 0.7580\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4251 - accuracy: 0.7948 - val_loss: 0.4712 - val_accuracy: 0.7617\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.4747 - val_accuracy: 0.7645\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4178 - accuracy: 0.7984 - val_loss: 0.4855 - val_accuracy: 0.7598\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4138 - accuracy: 0.8011 - val_loss: 0.4783 - val_accuracy: 0.7636\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4088 - accuracy: 0.8074 - val_loss: 0.4772 - val_accuracy: 0.7645\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4073 - accuracy: 0.8077 - val_loss: 0.4994 - val_accuracy: 0.7561\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4047 - accuracy: 0.8087 - val_loss: 0.4786 - val_accuracy: 0.7702\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3996 - accuracy: 0.8118 - val_loss: 0.4801 - val_accuracy: 0.7570\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8158 - val_loss: 0.4833 - val_accuracy: 0.7683\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8152 - val_loss: 0.4773 - val_accuracy: 0.7655\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3928 - accuracy: 0.8165 - val_loss: 0.4859 - val_accuracy: 0.7617\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3856 - accuracy: 0.8211 - val_loss: 0.4881 - val_accuracy: 0.7617\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3852 - accuracy: 0.8208 - val_loss: 0.4888 - val_accuracy: 0.7645\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3802 - accuracy: 0.8222 - val_loss: 0.4895 - val_accuracy: 0.7627\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3761 - accuracy: 0.8248 - val_loss: 0.4837 - val_accuracy: 0.7711\n",
      "Epoch 28/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3763 - accuracy: 0.8300 - val_loss: 0.4954 - val_accuracy: 0.7608\n",
      "Epoch 29/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3697 - accuracy: 0.8300 - val_loss: 0.4983 - val_accuracy: 0.7561\n",
      "Epoch 30/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8321 - val_loss: 0.4892 - val_accuracy: 0.7617\n",
      "Epoch 31/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3654 - accuracy: 0.8330 - val_loss: 0.5021 - val_accuracy: 0.7617\n",
      "Epoch 32/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8377 - val_loss: 0.5035 - val_accuracy: 0.7627\n",
      "Epoch 33/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8349 - val_loss: 0.4973 - val_accuracy: 0.7636\n",
      "Epoch 34/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3538 - accuracy: 0.8396 - val_loss: 0.5031 - val_accuracy: 0.7589\n",
      "Epoch 35/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3521 - accuracy: 0.8389 - val_loss: 0.5027 - val_accuracy: 0.7598\n",
      "Epoch 36/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8395 - val_loss: 0.5093 - val_accuracy: 0.7589\n",
      "Epoch 37/40\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.3460 - accuracy: 0.8486Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8488 - val_loss: 0.5056 - val_accuracy: 0.7627\n",
      "Epoch 00037: early stopping\n",
      "Test Accuracy: 77.11069583892822\n",
      "\n",
      "\n",
      "        acc1      acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
      "0  77.975631  77.22587  77.954972  77.673548  78.236395  79.080677  78.799248   \n",
      "\n",
      "        acc8       acc9      acc10        AVG  \n",
      "0  78.236395  77.673548  77.110696  77.996698  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Obtain the word to index\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model_2(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record2 = record2.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.975631</td>\n",
       "      <td>77.22587</td>\n",
       "      <td>77.954972</td>\n",
       "      <td>77.673548</td>\n",
       "      <td>78.236395</td>\n",
       "      <td>79.080677</td>\n",
       "      <td>78.799248</td>\n",
       "      <td>78.236395</td>\n",
       "      <td>77.673548</td>\n",
       "      <td>77.110696</td>\n",
       "      <td>77.996698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1      acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
       "0  77.975631  77.22587  77.954972  77.673548  78.236395  79.080677  78.799248   \n",
       "\n",
       "        acc8       acc9      acc10        AVG  \n",
       "0  78.236395  77.673548  77.110696  77.996698  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2\n",
    "report = report.to_excel('Emb_MLP_MR_2.xlsx', sheet_name='model_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_3(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=50, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 35,201\n",
      "Trainable params: 35,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = define_model_3(300)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5882 - accuracy: 0.6751 - val_loss: 0.4625 - val_accuracy: 0.7798\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4958 - accuracy: 0.7585 - val_loss: 0.4491 - val_accuracy: 0.7882\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4811 - accuracy: 0.7677 - val_loss: 0.4403 - val_accuracy: 0.7919\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.7731 - val_loss: 0.4447 - val_accuracy: 0.7873\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.7762 - val_loss: 0.4431 - val_accuracy: 0.7891\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.7807 - val_loss: 0.4419 - val_accuracy: 0.7891\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4485 - accuracy: 0.7831 - val_loss: 0.4392 - val_accuracy: 0.7938\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.7880 - val_loss: 0.4352 - val_accuracy: 0.7976\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4399 - accuracy: 0.7947 - val_loss: 0.4362 - val_accuracy: 0.7948\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4331 - accuracy: 0.7978 - val_loss: 0.4377 - val_accuracy: 0.7882\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4255 - accuracy: 0.7987 - val_loss: 0.4406 - val_accuracy: 0.7873\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4251 - accuracy: 0.8024 - val_loss: 0.4454 - val_accuracy: 0.7948\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4129 - accuracy: 0.8065 - val_loss: 0.4539 - val_accuracy: 0.8041\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4092 - accuracy: 0.8095 - val_loss: 0.4434 - val_accuracy: 0.7966\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4070 - accuracy: 0.8132 - val_loss: 0.4496 - val_accuracy: 0.7873\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3999 - accuracy: 0.8175 - val_loss: 0.4589 - val_accuracy: 0.7873\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3963 - accuracy: 0.8236 - val_loss: 0.4612 - val_accuracy: 0.7854\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3822 - accuracy: 0.8217 - val_loss: 0.4580 - val_accuracy: 0.7882\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3832 - accuracy: 0.8258 - val_loss: 0.4571 - val_accuracy: 0.7966\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3804 - accuracy: 0.8240 - val_loss: 0.5069 - val_accuracy: 0.7723\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8315 - val_loss: 0.4773 - val_accuracy: 0.7938\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3663 - accuracy: 0.8344 - val_loss: 0.4647 - val_accuracy: 0.7891\n",
      "Epoch 23/40\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.3540 - accuracy: 0.8413Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3534 - accuracy: 0.8410 - val_loss: 0.5148 - val_accuracy: 0.7873\n",
      "Epoch 00023: early stopping\n",
      "Test Accuracy: 80.41236996650696\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5787 - accuracy: 0.6874 - val_loss: 0.4953 - val_accuracy: 0.7516\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4945 - accuracy: 0.7603 - val_loss: 0.4962 - val_accuracy: 0.7507\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4791 - accuracy: 0.7702 - val_loss: 0.4904 - val_accuracy: 0.7629\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4668 - accuracy: 0.7746 - val_loss: 0.4928 - val_accuracy: 0.7488\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.7845 - val_loss: 0.4816 - val_accuracy: 0.7648\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.7851 - val_loss: 0.4846 - val_accuracy: 0.7648\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.7911 - val_loss: 0.4916 - val_accuracy: 0.7619\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.7965 - val_loss: 0.4833 - val_accuracy: 0.7666\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4304 - accuracy: 0.7980 - val_loss: 0.4829 - val_accuracy: 0.7629\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4318 - accuracy: 0.7976 - val_loss: 0.4871 - val_accuracy: 0.7769\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4246 - accuracy: 0.8007 - val_loss: 0.4888 - val_accuracy: 0.7779\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4170 - accuracy: 0.8070 - val_loss: 0.5145 - val_accuracy: 0.7554\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.8041 - val_loss: 0.4904 - val_accuracy: 0.7694\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.8088 - val_loss: 0.4910 - val_accuracy: 0.7769\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3989 - accuracy: 0.8189 - val_loss: 0.5014 - val_accuracy: 0.7676\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3912 - accuracy: 0.8211 - val_loss: 0.5059 - val_accuracy: 0.7666\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3930 - accuracy: 0.8163 - val_loss: 0.5140 - val_accuracy: 0.7666\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3856 - accuracy: 0.8213 - val_loss: 0.5169 - val_accuracy: 0.7732\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8302 - val_loss: 0.5042 - val_accuracy: 0.7554\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3701 - accuracy: 0.8327 - val_loss: 0.5306 - val_accuracy: 0.7685\n",
      "Epoch 21/40\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.3673 - accuracy: 0.8330Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3671 - accuracy: 0.8329 - val_loss: 0.5311 - val_accuracy: 0.7723\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 77.7881920337677\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5875 - accuracy: 0.6803 - val_loss: 0.4833 - val_accuracy: 0.7542\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.7583 - val_loss: 0.4707 - val_accuracy: 0.7627\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.7744 - val_loss: 0.4693 - val_accuracy: 0.7617\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4699 - accuracy: 0.7723 - val_loss: 0.4578 - val_accuracy: 0.7674\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.7804 - val_loss: 0.4507 - val_accuracy: 0.7655\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.7887 - val_loss: 0.4508 - val_accuracy: 0.7739\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4482 - accuracy: 0.7862 - val_loss: 0.4445 - val_accuracy: 0.7739\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.7892 - val_loss: 0.4427 - val_accuracy: 0.7767\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.7946 - val_loss: 0.4485 - val_accuracy: 0.7758\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4303 - accuracy: 0.7968 - val_loss: 0.4492 - val_accuracy: 0.7777\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4275 - accuracy: 0.7965 - val_loss: 0.4422 - val_accuracy: 0.7861\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8017 - val_loss: 0.4415 - val_accuracy: 0.7814\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8097 - val_loss: 0.4571 - val_accuracy: 0.7889\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4107 - accuracy: 0.8119 - val_loss: 0.4578 - val_accuracy: 0.7777\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8185 - val_loss: 0.4497 - val_accuracy: 0.7758\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3987 - accuracy: 0.8176 - val_loss: 0.4489 - val_accuracy: 0.7899\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3886 - accuracy: 0.8209 - val_loss: 0.4560 - val_accuracy: 0.7749\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3853 - accuracy: 0.8202 - val_loss: 0.4515 - val_accuracy: 0.7824\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.8270 - val_loss: 0.4539 - val_accuracy: 0.7749\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3752 - accuracy: 0.8309 - val_loss: 0.4635 - val_accuracy: 0.7805\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3679 - accuracy: 0.8327 - val_loss: 0.4536 - val_accuracy: 0.7833\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3575 - accuracy: 0.8419 - val_loss: 0.4604 - val_accuracy: 0.7795\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3594 - accuracy: 0.8343 - val_loss: 0.4583 - val_accuracy: 0.7833\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8417 - val_loss: 0.4619 - val_accuracy: 0.7739\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8480 - val_loss: 0.4703 - val_accuracy: 0.7786\n",
      "Epoch 26/40\n",
      "279/300 [==========================>...] - ETA: 0s - loss: 0.3393 - accuracy: 0.8513Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8509 - val_loss: 0.4762 - val_accuracy: 0.7786\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 78.98686528205872\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5842 - accuracy: 0.6828 - val_loss: 0.5035 - val_accuracy: 0.7486\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.7619 - val_loss: 0.4853 - val_accuracy: 0.7608\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4778 - accuracy: 0.7724 - val_loss: 0.4748 - val_accuracy: 0.7636\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.7769 - val_loss: 0.4833 - val_accuracy: 0.7636\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.7832 - val_loss: 0.4869 - val_accuracy: 0.7589\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.7849 - val_loss: 0.4810 - val_accuracy: 0.7655\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4445 - accuracy: 0.7871 - val_loss: 0.4990 - val_accuracy: 0.7580\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4362 - accuracy: 0.7931 - val_loss: 0.4864 - val_accuracy: 0.7645\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4326 - accuracy: 0.7929 - val_loss: 0.5090 - val_accuracy: 0.7598\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.7997 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4228 - accuracy: 0.8024 - val_loss: 0.4757 - val_accuracy: 0.7598\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4154 - accuracy: 0.8084 - val_loss: 0.4905 - val_accuracy: 0.7608\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4095 - accuracy: 0.8091 - val_loss: 0.4891 - val_accuracy: 0.7636\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4036 - accuracy: 0.8101 - val_loss: 0.5051 - val_accuracy: 0.7570\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8115 - val_loss: 0.4877 - val_accuracy: 0.7627\n",
      "Epoch 16/40\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8230Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3901 - accuracy: 0.8232 - val_loss: 0.4841 - val_accuracy: 0.7655\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 76.54784321784973\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.6723 - val_loss: 0.4993 - val_accuracy: 0.7589\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4917 - accuracy: 0.7631 - val_loss: 0.4800 - val_accuracy: 0.7758\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4789 - accuracy: 0.7690 - val_loss: 0.4771 - val_accuracy: 0.7692\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4677 - accuracy: 0.7744 - val_loss: 0.4716 - val_accuracy: 0.7739\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4548 - accuracy: 0.7843 - val_loss: 0.4765 - val_accuracy: 0.7758\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4482 - accuracy: 0.7858 - val_loss: 0.4748 - val_accuracy: 0.7702\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4458 - accuracy: 0.7900 - val_loss: 0.4739 - val_accuracy: 0.7711\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.7903 - val_loss: 0.4826 - val_accuracy: 0.7683\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4357 - accuracy: 0.7961 - val_loss: 0.4745 - val_accuracy: 0.7758\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4320 - accuracy: 0.7941 - val_loss: 0.4780 - val_accuracy: 0.7767\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4193 - accuracy: 0.8017 - val_loss: 0.4868 - val_accuracy: 0.7711\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4164 - accuracy: 0.8062 - val_loss: 0.4960 - val_accuracy: 0.7795\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4139 - accuracy: 0.8087 - val_loss: 0.4856 - val_accuracy: 0.7842\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4016 - accuracy: 0.8159 - val_loss: 0.4929 - val_accuracy: 0.7795\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4010 - accuracy: 0.8148 - val_loss: 0.4846 - val_accuracy: 0.7777\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8130 - val_loss: 0.4881 - val_accuracy: 0.7749\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3875 - accuracy: 0.8202 - val_loss: 0.4913 - val_accuracy: 0.7749\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3837 - accuracy: 0.8229 - val_loss: 0.5038 - val_accuracy: 0.7749\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3751 - accuracy: 0.8274 - val_loss: 0.4931 - val_accuracy: 0.7805\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8305 - val_loss: 0.5021 - val_accuracy: 0.7758\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3660 - accuracy: 0.8335 - val_loss: 0.5181 - val_accuracy: 0.7814\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.8372 - val_loss: 0.5088 - val_accuracy: 0.7692\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298/300 [============================>.] - ETA: 0s - loss: 0.3543 - accuracy: 0.8386Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3539 - accuracy: 0.8389 - val_loss: 0.5310 - val_accuracy: 0.7730\n",
      "Epoch 00023: early stopping\n",
      "Test Accuracy: 78.42401266098022\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5861 - accuracy: 0.6788 - val_loss: 0.4874 - val_accuracy: 0.7730\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4974 - accuracy: 0.7608 - val_loss: 0.4732 - val_accuracy: 0.7852\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4783 - accuracy: 0.7672 - val_loss: 0.4613 - val_accuracy: 0.7767\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4671 - accuracy: 0.7767 - val_loss: 0.4628 - val_accuracy: 0.7739\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.7804 - val_loss: 0.4635 - val_accuracy: 0.7730\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4522 - accuracy: 0.7828 - val_loss: 0.4647 - val_accuracy: 0.7767\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.7874 - val_loss: 0.4680 - val_accuracy: 0.7777\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.7888 - val_loss: 0.4788 - val_accuracy: 0.7645\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4338 - accuracy: 0.7946 - val_loss: 0.4727 - val_accuracy: 0.7720\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4320 - accuracy: 0.7964 - val_loss: 0.4724 - val_accuracy: 0.7730\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.8025 - val_loss: 0.4797 - val_accuracy: 0.7692\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.7994Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4219 - accuracy: 0.7994 - val_loss: 0.4689 - val_accuracy: 0.7767\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 78.51782441139221\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5905 - accuracy: 0.6784 - val_loss: 0.4926 - val_accuracy: 0.7636\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.7561 - val_loss: 0.4738 - val_accuracy: 0.7739\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4807 - accuracy: 0.7719 - val_loss: 0.4622 - val_accuracy: 0.7758\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4719 - accuracy: 0.7714 - val_loss: 0.4550 - val_accuracy: 0.7767\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4617 - accuracy: 0.7832 - val_loss: 0.4541 - val_accuracy: 0.7608\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.4642 - val_accuracy: 0.7730\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4450 - accuracy: 0.7867 - val_loss: 0.4519 - val_accuracy: 0.7833\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4437 - accuracy: 0.7911 - val_loss: 0.4524 - val_accuracy: 0.7617\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.7913 - val_loss: 0.4543 - val_accuracy: 0.7589\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.7999 - val_loss: 0.4507 - val_accuracy: 0.7833\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4260 - accuracy: 0.8013 - val_loss: 0.4519 - val_accuracy: 0.7711\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4176 - accuracy: 0.8026 - val_loss: 0.4822 - val_accuracy: 0.7655\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4170 - accuracy: 0.8051 - val_loss: 0.4586 - val_accuracy: 0.7627\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4084 - accuracy: 0.8103 - val_loss: 0.4621 - val_accuracy: 0.7664\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8148 - val_loss: 0.4810 - val_accuracy: 0.7495\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4033 - accuracy: 0.8129 - val_loss: 0.4628 - val_accuracy: 0.7702\n",
      "Epoch 17/40\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.3938 - accuracy: 0.8157Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3938 - accuracy: 0.8158 - val_loss: 0.4730 - val_accuracy: 0.7749\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 78.33020687103271\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6765 - val_loss: 0.5228 - val_accuracy: 0.7373\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4945 - accuracy: 0.7613 - val_loss: 0.5062 - val_accuracy: 0.7430\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4723 - accuracy: 0.7711 - val_loss: 0.4962 - val_accuracy: 0.7467\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.7744 - val_loss: 0.4938 - val_accuracy: 0.7430\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4546 - accuracy: 0.7842 - val_loss: 0.4938 - val_accuracy: 0.7533\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.7842 - val_loss: 0.4907 - val_accuracy: 0.7486\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4471 - accuracy: 0.7905 - val_loss: 0.4924 - val_accuracy: 0.7439\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4404 - accuracy: 0.7929 - val_loss: 0.4928 - val_accuracy: 0.7495\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4323 - accuracy: 0.7979 - val_loss: 0.4929 - val_accuracy: 0.7533\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4260 - accuracy: 0.8019 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4221 - accuracy: 0.8019 - val_loss: 0.4889 - val_accuracy: 0.7645\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4174 - accuracy: 0.8005 - val_loss: 0.5061 - val_accuracy: 0.7523\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8077 - val_loss: 0.5096 - val_accuracy: 0.7523\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4082 - accuracy: 0.8088 - val_loss: 0.5056 - val_accuracy: 0.7430\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4013 - accuracy: 0.8140 - val_loss: 0.5093 - val_accuracy: 0.7589\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3945 - accuracy: 0.8233 - val_loss: 0.4909 - val_accuracy: 0.7561\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3905 - accuracy: 0.8197 - val_loss: 0.5082 - val_accuracy: 0.7542\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3797 - accuracy: 0.8231 - val_loss: 0.5004 - val_accuracy: 0.7674\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3844 - accuracy: 0.8237 - val_loss: 0.5122 - val_accuracy: 0.7542\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8295 - val_loss: 0.5365 - val_accuracy: 0.7589\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8342 - val_loss: 0.5269 - val_accuracy: 0.7627\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3672 - accuracy: 0.8334 - val_loss: 0.5168 - val_accuracy: 0.7580\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3573 - accuracy: 0.8366 - val_loss: 0.5087 - val_accuracy: 0.7617\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8455 - val_loss: 0.5336 - val_accuracy: 0.7570\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8451 - val_loss: 0.5429 - val_accuracy: 0.7598\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8462 - val_loss: 0.5258 - val_accuracy: 0.7523\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8525 - val_loss: 0.5293 - val_accuracy: 0.7561\n",
      "Epoch 28/40\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.8516Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3287 - accuracy: 0.8518 - val_loss: 0.5457 - val_accuracy: 0.7598\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 76.73546075820923\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5986 - accuracy: 0.6758 - val_loss: 0.5165 - val_accuracy: 0.7458\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4959 - accuracy: 0.7616 - val_loss: 0.5130 - val_accuracy: 0.7458\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4763 - accuracy: 0.7685 - val_loss: 0.4939 - val_accuracy: 0.7561\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4650 - accuracy: 0.7773 - val_loss: 0.4984 - val_accuracy: 0.7505\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4549 - accuracy: 0.7850 - val_loss: 0.4901 - val_accuracy: 0.7627\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.7860 - val_loss: 0.4972 - val_accuracy: 0.7627\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4417 - accuracy: 0.7924 - val_loss: 0.4904 - val_accuracy: 0.7598\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4336 - accuracy: 0.7952 - val_loss: 0.4899 - val_accuracy: 0.7730\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4333 - accuracy: 0.7952 - val_loss: 0.4913 - val_accuracy: 0.7645\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.7997 - val_loss: 0.4977 - val_accuracy: 0.7627\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4221 - accuracy: 0.8037 - val_loss: 0.4991 - val_accuracy: 0.7636\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4129 - accuracy: 0.8077 - val_loss: 0.5013 - val_accuracy: 0.7608\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4079 - accuracy: 0.8117 - val_loss: 0.4961 - val_accuracy: 0.7617\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4069 - accuracy: 0.8154 - val_loss: 0.5039 - val_accuracy: 0.7589\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4032 - accuracy: 0.8120 - val_loss: 0.4938 - val_accuracy: 0.7702\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3904 - accuracy: 0.8191 - val_loss: 0.5073 - val_accuracy: 0.7636\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3834 - accuracy: 0.8210 - val_loss: 0.5061 - val_accuracy: 0.7645\n",
      "Epoch 18/40\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.3799 - accuracy: 0.8255Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3812 - accuracy: 0.8237 - val_loss: 0.5124 - val_accuracy: 0.7580\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 77.29831337928772\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5853 - accuracy: 0.6781 - val_loss: 0.4845 - val_accuracy: 0.7617\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4932 - accuracy: 0.7617 - val_loss: 0.4554 - val_accuracy: 0.7861\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.7667 - val_loss: 0.4665 - val_accuracy: 0.7720\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4683 - accuracy: 0.7746 - val_loss: 0.4417 - val_accuracy: 0.7927\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4605 - accuracy: 0.7783 - val_loss: 0.4416 - val_accuracy: 0.7889\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.7855 - val_loss: 0.4408 - val_accuracy: 0.7955\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4510 - accuracy: 0.7838 - val_loss: 0.4487 - val_accuracy: 0.7899\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.7939 - val_loss: 0.4368 - val_accuracy: 0.8011\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4335 - accuracy: 0.7931 - val_loss: 0.4316 - val_accuracy: 0.7899\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4313 - accuracy: 0.7956 - val_loss: 0.4402 - val_accuracy: 0.7880\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4270 - accuracy: 0.7993 - val_loss: 0.4364 - val_accuracy: 0.8011\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8002 - val_loss: 0.4326 - val_accuracy: 0.7936\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4177 - accuracy: 0.8034 - val_loss: 0.4368 - val_accuracy: 0.7917\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4096 - accuracy: 0.8090 - val_loss: 0.4365 - val_accuracy: 0.7899\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4018 - accuracy: 0.8120 - val_loss: 0.4599 - val_accuracy: 0.7824\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3987 - accuracy: 0.8189 - val_loss: 0.4486 - val_accuracy: 0.7805\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3944 - accuracy: 0.8201 - val_loss: 0.4479 - val_accuracy: 0.7842\n",
      "Epoch 18/40\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.3902 - accuracy: 0.8230Restoring model weights from the end of the best epoch.\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3907 - accuracy: 0.8225 - val_loss: 0.4635 - val_accuracy: 0.7805\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 80.1125705242157\n",
      "\n",
      "\n",
      "       acc1       acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
      "0  80.41237  77.788192  78.986865  76.547843  78.424013  78.517824  78.330207   \n",
      "\n",
      "        acc8       acc9      acc10        AVG  \n",
      "0  76.735461  77.298313  80.112571  78.315366  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Define the word_index\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model_3(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record3 = record3.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record3)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.41237</td>\n",
       "      <td>77.788192</td>\n",
       "      <td>78.986865</td>\n",
       "      <td>76.547843</td>\n",
       "      <td>78.424013</td>\n",
       "      <td>78.517824</td>\n",
       "      <td>78.330207</td>\n",
       "      <td>76.735461</td>\n",
       "      <td>77.298313</td>\n",
       "      <td>80.112571</td>\n",
       "      <td>78.315366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc1       acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
       "0  80.41237  77.788192  78.986865  76.547843  78.424013  78.517824  78.330207   \n",
       "\n",
       "        acc8       acc9      acc10        AVG  \n",
       "0  76.735461  77.298313  80.112571  78.315366  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3\n",
    "report = report.to_excel('Emb_MLP_MR_3.xlsx', sheet_name='model_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
