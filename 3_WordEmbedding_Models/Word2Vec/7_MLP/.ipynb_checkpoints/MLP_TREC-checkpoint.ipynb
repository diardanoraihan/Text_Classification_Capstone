{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classification with CR Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using Multi Layer Perceptron on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5952, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>who was the 22nd president of the us ?</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>what is the money they use in zambia ?</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>how many feet in a mile ?</td>\n",
       "      <td>5</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>what is the birthstone of october ?</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>what is e coli ?</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     how did serfdom develop in and then leave russ...      0  train\n",
       "1      what films featured the character popeye doyle ?      1  train\n",
       "2     how can i find a list of celebrities ' real na...      0  train\n",
       "3     what fowl grabs the spotlight after the chines...      1  train\n",
       "4                       what is the full form of .com ?      2  train\n",
       "...                                                 ...    ...    ...\n",
       "5947             who was the 22nd president of the us ?      3   test\n",
       "5948             what is the money they use in zambia ?      1   test\n",
       "5949                          how many feet in a mile ?      5   test\n",
       "5950                what is the birthstone of october ?      1   test\n",
       "5951                                   what is e coli ?      0   test\n",
       "\n",
       "[5952 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/TREC/TREC.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5952 entries, 0 to 5951\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  5952 non-null   object\n",
      " 1   label     5952 non-null   int32 \n",
      " 2   split     5952 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 116.4+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">train</th>\n",
       "      <th>0</th>\n",
       "      <td>1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentence\n",
       "split label          \n",
       "test  0           138\n",
       "      1            94\n",
       "      2             9\n",
       "      3            65\n",
       "      4            81\n",
       "      5           113\n",
       "train 0          1162\n",
       "      1          1250\n",
       "      2            86\n",
       "      3          1223\n",
       "      4           835\n",
       "      5           896"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby(by=['split', 'label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>5452</td>\n",
       "      <td>5452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  label\n",
       "split                 \n",
       "test        500    500\n",
       "train      5452   5452"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='split').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452\n",
      "5452\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "# Separate the sentences and the labels for training and testing\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Word2Vec Static\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Word Embedding: Word2Vec\n",
    "\n",
    "__1. Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7526 words present from 8761 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "oov_tok = '<OOV>'\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `clean_doc` function\n",
    "__2. Define a function to clean the document called __`clean_doc()`____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(sentences, word_index):\n",
    "    clean_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower().split()\n",
    "        clean_word = []\n",
    "        for word in sentence:\n",
    "            if word in word_index:\n",
    "                clean_word.append(word)\n",
    "        clean_sentence = ' '.join(clean_word)\n",
    "        clean_sentences.append(clean_sentence)\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how did serfdom develop in and then leave russia',\n",
       " 'what films featured the character popeye doyle',\n",
       " \"how can i find a list of celebrities ' real names\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences = clean_doc(train_x, word_index)\n",
    "clean_sentences[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `sentence_to_avg` function\n",
    "__3. Define a `sentence_to_avg` function__\n",
    "\n",
    "We will use this function to calculate the mean of word embedding representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Split sentence into list of lower case words (≈ 1 line)\n",
    "    words = (sentence.lower()).split()\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros(word2vec.word_vec('i').shape)\n",
    "    \n",
    "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in word_to_vec_map:\n",
    "            total += word_to_vec_map.word_vec(w)\n",
    "            count += 1\n",
    "            \n",
    "    if count!= 0:\n",
    "        avg = total/count\n",
    "    else:\n",
    "        avg\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.22558594\n",
      "-0.16699219\n",
      "0.11376953\n",
      "the mean of word embedding is:  -0.09293619791666667\n"
     ]
    }
   ],
   "source": [
    "i = word2vec.word_vec('i')[0]\n",
    "print(word2vec.word_vec('i')[0])\n",
    "j = word2vec.word_vec('am')[0]\n",
    "print(word2vec.word_vec('am')[0])\n",
    "k = word2vec.word_vec('handsome')[0]\n",
    "print(word2vec.word_vec('handsome')[0])\n",
    "mean = (i+j+k)/3\n",
    "print('the mean of word embedding is: ', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0929362 ,  0.03125   , -0.03914388,  0.09879557,  0.07088598,\n",
       "        0.03092448, -0.00651042, -0.04437256,  0.08068848,  0.07242838,\n",
       "        0.00160726, -0.10530599, -0.07389323, -0.08854166,  0.00565592,\n",
       "        0.15136719, -0.0460612 ,  0.19482422,  0.1101888 ,  0.05924479,\n",
       "       -0.18457031,  0.00716146,  0.16153972,  0.02437337, -0.01578776,\n",
       "        0.06119792, -0.25048828,  0.02799479,  0.0853475 , -0.14029948,\n",
       "        0.13688152, -0.01350911, -0.05493164, -0.01090495,  0.03352864,\n",
       "        0.09635416, -0.04239909,  0.00777181, -0.1438802 ,  0.06510416,\n",
       "        0.14560954, -0.11295573,  0.25520834,  0.08833822,  0.14339192,\n",
       "        0.037028  , -0.02832031, -0.00139872,  0.00309245, -0.17871094,\n",
       "        0.06852213,  0.07910156,  0.09513346,  0.11425781, -0.00488281,\n",
       "        0.11051432, -0.01139323, -0.08479818, -0.09277344, -0.03263346,\n",
       "       -0.00374349,  0.07977295, -0.26416016, -0.05135091,  0.06111654,\n",
       "       -0.06933594, -0.06486002,  0.18766277, -0.04826609,  0.03304036,\n",
       "        0.24267578,  0.11425781,  0.02310689,  0.06697591, -0.19010417,\n",
       "        0.03230794,  0.00317383, -0.03739421,  0.12434896,  0.1574707 ,\n",
       "       -0.05745443,  0.015625  ,  0.01456706, -0.05794271, -0.0549113 ,\n",
       "        0.0398763 , -0.01517741,  0.11263021, -0.03271484,  0.06758627,\n",
       "       -0.09594727,  0.06559245,  0.00217692,  0.03627523, -0.03776042,\n",
       "        0.02945963, -0.05960592, -0.02514648,  0.07128906, -0.04410807,\n",
       "       -0.21533203, -0.02174886, -0.05029297,  0.04264323,  0.08194987,\n",
       "        0.05502828,  0.09375   , -0.02050781,  0.04243978, -0.1439616 ,\n",
       "        0.        , -0.17805989,  0.0822347 ,  0.00140381,  0.17220052,\n",
       "       -0.08251953,  0.00450643, -0.24837239,  0.14001465,  0.01749674,\n",
       "        0.24576823, -0.06986491, -0.04370117,  0.01497396, -0.01534017,\n",
       "        0.09863281, -0.12027995,  0.14615886,  0.19580078,  0.08813477,\n",
       "       -0.2861328 , -0.0653483 , -0.03889974, -0.07784017, -0.12190755,\n",
       "       -0.04427083, -0.06233724,  0.08296712,  0.12670898,  0.1593221 ,\n",
       "        0.04296875,  0.08544922, -0.01513672,  0.        , -0.2101237 ,\n",
       "        0.11390177, -0.01127116, -0.06298828,  0.0198822 , -0.03000895,\n",
       "       -0.05118815, -0.00195312, -0.1007487 ,  0.09879557, -0.19702148,\n",
       "       -0.05611674, -0.03466797,  0.13932292, -0.0764974 , -0.00777181,\n",
       "        0.05948893,  0.11360677,  0.01757812,  0.07926432, -0.0104777 ,\n",
       "       -0.16145833,  0.17708333,  0.13507843, -0.06380209,  0.10839844,\n",
       "       -0.21500652, -0.0933431 ,  0.05853271, -0.14601643, -0.0369873 ,\n",
       "        0.02945963,  0.2747396 , -0.07006454,  0.06966146, -0.17203777,\n",
       "       -0.02294922, -0.09220377, -0.01790492, -0.0111084 , -0.03776042,\n",
       "        0.03540039, -0.03483073,  0.0764974 ,  0.07096354, -0.13916016,\n",
       "       -0.01989746,  0.06176758, -0.11336263, -0.03279241,  0.08687337,\n",
       "        0.15901692, -0.07185873,  0.02547201, -0.03220622, -0.125     ,\n",
       "       -0.12727864,  0.02563477, -0.06311035, -0.16959636, -0.10058594,\n",
       "       -0.05464681, -0.09391276,  0.06502279, -0.06184896,  0.14835612,\n",
       "       -0.1031901 ,  0.07779948, -0.06420898, -0.0892334 , -0.20214844,\n",
       "        0.13671875,  0.11507162, -0.00145467, -0.23079427, -0.04801432,\n",
       "       -0.06262207,  0.07454427,  0.0298055 , -0.01489258,  0.08854166,\n",
       "       -0.1608073 , -0.00372314, -0.056722  , -0.06841787, -0.16031902,\n",
       "        0.1538086 , -0.03597005, -0.09985352, -0.03483073,  0.07324219,\n",
       "        0.03672282,  0.03737386,  0.06705729,  0.10375977,  0.04850261,\n",
       "        0.20996094,  0.06673177,  0.03833008,  0.06363932, -0.18758138,\n",
       "       -0.10904948, -0.02693685,  0.02254232, -0.08405808,  0.02848307,\n",
       "        0.17675781,  0.01188151,  0.08610026,  0.18359375,  0.0764974 ,\n",
       "        0.03463237,  0.08015951,  0.00455729, -0.15309651,  0.00195312,\n",
       "        0.0965983 , -0.18180339, -0.02457682, -0.01757812, -0.08410645,\n",
       "        0.20092773, -0.12624104, -0.09566244, -0.03291829, -0.04532878,\n",
       "        0.04199219, -0.01635742,  0.04329427,  0.06469727,  0.04390462,\n",
       "        0.03625488, -0.04744466, -0.14420573, -0.17626953,  0.18603516,\n",
       "        0.01155599,  0.06009929, -0.02880859,  0.06738281,  0.0949707 ,\n",
       "        0.00325521, -0.07470703, -0.18782552, -0.00447591,  0.06038411,\n",
       "        0.0456543 ,  0.10611979, -0.11393229, -0.05623372, -0.03450521,\n",
       "        0.02193197, -0.12263998, -0.08158366, -0.0332845 ,  0.09596761],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the functions used in a sentence\n",
    "mysentence = 'I am handsome'\n",
    "sentence_to_avg(mysentence, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Sentence into Word2Vec Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_sentences(sentences):\n",
    "\n",
    "    encoded_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        encoded_sentence = sentence_to_avg(sentence, word2vec)\n",
    "        encoded_sentences.append(encoded_sentence)\n",
    "\n",
    "    encoded_sentences = np.array(encoded_sentences)\n",
    "    return encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5452, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.06625366,  0.01227188,  0.07821655, ..., -0.01962137,\n",
       "         0.04184723, -0.01075745],\n",
       "       [ 0.02888997,  0.08051554, -0.00393168, ..., -0.03134155,\n",
       "        -0.00695801, -0.00199382],\n",
       "       [ 0.03599548,  0.08511353,  0.02099609, ...,  0.00486755,\n",
       "        -0.06564331, -0.03824615],\n",
       "       ...,\n",
       "       [-0.01763306,  0.00096436,  0.08427735, ...,  0.06772461,\n",
       "         0.09284668, -0.05214844],\n",
       "       [-0.0278066 ,  0.04503377,  0.07877604, ...,  0.04292806,\n",
       "         0.07348633,  0.02534994],\n",
       "       [-0.00012716, -0.05644735,  0.00537109, ...,  0.03894043,\n",
       "         0.00477091, -0.02848307]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = encoded_sentences(clean_sentences)\n",
    "print(embedded_sentences.shape)\n",
    "embedded_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=50, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=6, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 50)                15050     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 15,356\n",
      "Trainable params: 15,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model(300)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "'''\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=30, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5393 - accuracy: 0.3890 - val_loss: 1.1778 - val_accuracy: 0.5840\n",
      "Epoch 2/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 1.2019 - accuracy: 0.5565 - val_loss: 0.9228 - val_accuracy: 0.6720\n",
      "Epoch 3/100\n",
      "171/171 [==============================] - 0s 913us/step - loss: 1.0311 - accuracy: 0.6275 - val_loss: 0.7896 - val_accuracy: 0.7140\n",
      "Epoch 4/100\n",
      "171/171 [==============================] - 0s 922us/step - loss: 0.9497 - accuracy: 0.6486 - val_loss: 0.6862 - val_accuracy: 0.7760\n",
      "Epoch 5/100\n",
      "171/171 [==============================] - 0s 977us/step - loss: 0.8781 - accuracy: 0.6904 - val_loss: 0.6381 - val_accuracy: 0.7860\n",
      "Epoch 6/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.8368 - accuracy: 0.7001 - val_loss: 0.6183 - val_accuracy: 0.7860\n",
      "Epoch 7/100\n",
      "171/171 [==============================] - 0s 939us/step - loss: 0.8012 - accuracy: 0.7051 - val_loss: 0.5703 - val_accuracy: 0.8140\n",
      "Epoch 8/100\n",
      "171/171 [==============================] - 0s 985us/step - loss: 0.7657 - accuracy: 0.7183 - val_loss: 0.5577 - val_accuracy: 0.8160\n",
      "Epoch 9/100\n",
      "171/171 [==============================] - 0s 972us/step - loss: 0.7450 - accuracy: 0.7342 - val_loss: 0.5372 - val_accuracy: 0.8260\n",
      "Epoch 10/100\n",
      "171/171 [==============================] - 0s 975us/step - loss: 0.7265 - accuracy: 0.7373 - val_loss: 0.5304 - val_accuracy: 0.8200\n",
      "Epoch 11/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.7423 - val_loss: 0.5299 - val_accuracy: 0.8200\n",
      "Epoch 12/100\n",
      "171/171 [==============================] - 0s 986us/step - loss: 0.6930 - accuracy: 0.7494 - val_loss: 0.5104 - val_accuracy: 0.8260\n",
      "Epoch 13/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.7649 - val_loss: 0.5112 - val_accuracy: 0.8180\n",
      "Epoch 14/100\n",
      "171/171 [==============================] - 0s 924us/step - loss: 0.6639 - accuracy: 0.7594 - val_loss: 0.5103 - val_accuracy: 0.8220\n",
      "Epoch 15/100\n",
      "171/171 [==============================] - 0s 895us/step - loss: 0.6508 - accuracy: 0.7628 - val_loss: 0.4975 - val_accuracy: 0.8240\n",
      "Epoch 16/100\n",
      "171/171 [==============================] - 0s 968us/step - loss: 0.6295 - accuracy: 0.7691 - val_loss: 0.4755 - val_accuracy: 0.8360\n",
      "Epoch 17/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.7746 - val_loss: 0.4854 - val_accuracy: 0.8280\n",
      "Epoch 18/100\n",
      "171/171 [==============================] - 0s 966us/step - loss: 0.6106 - accuracy: 0.7775 - val_loss: 0.4768 - val_accuracy: 0.8360\n",
      "Epoch 19/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.6031 - accuracy: 0.78 - 0s 1ms/step - loss: 0.6079 - accuracy: 0.7812 - val_loss: 0.4676 - val_accuracy: 0.8300\n",
      "Epoch 20/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.7830 - val_loss: 0.4759 - val_accuracy: 0.8340\n",
      "Epoch 21/100\n",
      "171/171 [==============================] - 0s 943us/step - loss: 0.5833 - accuracy: 0.7880 - val_loss: 0.4750 - val_accuracy: 0.8300\n",
      "Epoch 22/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.7876 - val_loss: 0.4783 - val_accuracy: 0.8300\n",
      "Epoch 23/100\n",
      "171/171 [==============================] - 0s 958us/step - loss: 0.5695 - accuracy: 0.7929 - val_loss: 0.4736 - val_accuracy: 0.8300\n",
      "Epoch 24/100\n",
      "171/171 [==============================] - 0s 957us/step - loss: 0.5722 - accuracy: 0.7927 - val_loss: 0.4605 - val_accuracy: 0.8420\n",
      "Epoch 25/100\n",
      "171/171 [==============================] - 0s 969us/step - loss: 0.5637 - accuracy: 0.7951 - val_loss: 0.4818 - val_accuracy: 0.8220\n",
      "Epoch 26/100\n",
      "171/171 [==============================] - 0s 934us/step - loss: 0.5483 - accuracy: 0.8034 - val_loss: 0.4630 - val_accuracy: 0.8420\n",
      "Epoch 27/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7944 - val_loss: 0.4606 - val_accuracy: 0.8380\n",
      "Epoch 28/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.8032 - val_loss: 0.4501 - val_accuracy: 0.8440\n",
      "Epoch 29/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.8058 - val_loss: 0.4508 - val_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "171/171 [==============================] - 0s 961us/step - loss: 0.5164 - accuracy: 0.8107 - val_loss: 0.4450 - val_accuracy: 0.8480\n",
      "Epoch 31/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.8135 - val_loss: 0.4560 - val_accuracy: 0.8440\n",
      "Epoch 32/100\n",
      "171/171 [==============================] - 0s 968us/step - loss: 0.5110 - accuracy: 0.8127 - val_loss: 0.4462 - val_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "171/171 [==============================] - 0s 979us/step - loss: 0.5041 - accuracy: 0.8136 - val_loss: 0.4450 - val_accuracy: 0.8460\n",
      "Epoch 34/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8197 - val_loss: 0.4404 - val_accuracy: 0.8440\n",
      "Epoch 35/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.8236 - val_loss: 0.4450 - val_accuracy: 0.8420\n",
      "Epoch 36/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8204 - val_loss: 0.4448 - val_accuracy: 0.8380\n",
      "Epoch 37/100\n",
      "171/171 [==============================] - 0s 899us/step - loss: 0.4753 - accuracy: 0.8296 - val_loss: 0.4511 - val_accuracy: 0.8340\n",
      "Epoch 38/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.8281 - val_loss: 0.4355 - val_accuracy: 0.8380\n",
      "Epoch 39/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.8247 - val_loss: 0.4271 - val_accuracy: 0.8420\n",
      "Epoch 40/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.8303 - val_loss: 0.4427 - val_accuracy: 0.8360\n",
      "Epoch 41/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.8355 - val_loss: 0.4328 - val_accuracy: 0.8360\n",
      "Epoch 42/100\n",
      "171/171 [==============================] - 0s 903us/step - loss: 0.4660 - accuracy: 0.8313 - val_loss: 0.4503 - val_accuracy: 0.8380\n",
      "Epoch 43/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.8360 - val_loss: 0.4473 - val_accuracy: 0.8340\n",
      "Epoch 44/100\n",
      "171/171 [==============================] - 0s 900us/step - loss: 0.4544 - accuracy: 0.8335 - val_loss: 0.4645 - val_accuracy: 0.8260\n",
      "Epoch 45/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.8391 - val_loss: 0.4419 - val_accuracy: 0.8400\n",
      "Epoch 46/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.8446 - val_loss: 0.4451 - val_accuracy: 0.8380\n",
      "Epoch 47/100\n",
      "171/171 [==============================] - 0s 926us/step - loss: 0.4387 - accuracy: 0.8459 - val_loss: 0.4346 - val_accuracy: 0.8400\n",
      "Epoch 48/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8428 - val_loss: 0.4308 - val_accuracy: 0.8360\n",
      "Epoch 49/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.8452 - val_loss: 0.4525 - val_accuracy: 0.8380\n",
      "Epoch 50/100\n",
      "171/171 [==============================] - 0s 984us/step - loss: 0.4322 - accuracy: 0.8450 - val_loss: 0.4517 - val_accuracy: 0.8280\n",
      "Epoch 51/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.8461 - val_loss: 0.4490 - val_accuracy: 0.8420\n",
      "Epoch 52/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8511 - val_loss: 0.4301 - val_accuracy: 0.8440\n",
      "Epoch 53/100\n",
      "171/171 [==============================] - 0s 951us/step - loss: 0.4213 - accuracy: 0.8432 - val_loss: 0.4341 - val_accuracy: 0.8380\n",
      "Epoch 54/100\n",
      "171/171 [==============================] - 0s 973us/step - loss: 0.4071 - accuracy: 0.8467 - val_loss: 0.4357 - val_accuracy: 0.8380\n",
      "Epoch 55/100\n",
      "171/171 [==============================] - 0s 947us/step - loss: 0.4057 - accuracy: 0.8518 - val_loss: 0.4278 - val_accuracy: 0.8420\n",
      "Epoch 56/100\n",
      "171/171 [==============================] - 0s 972us/step - loss: 0.4014 - accuracy: 0.8560 - val_loss: 0.4542 - val_accuracy: 0.8340\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8606 - val_loss: 0.4500 - val_accuracy: 0.8220\n",
      "Epoch 58/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.85 - 0s 958us/step - loss: 0.3918 - accuracy: 0.8549 - val_loss: 0.4515 - val_accuracy: 0.8360\n",
      "Epoch 59/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8648 - val_loss: 0.4712 - val_accuracy: 0.8340\n",
      "Epoch 60/100\n",
      "171/171 [==============================] - 0s 955us/step - loss: 0.3925 - accuracy: 0.8558 - val_loss: 0.4583 - val_accuracy: 0.8340\n",
      "Epoch 61/100\n",
      "171/171 [==============================] - 0s 946us/step - loss: 0.3853 - accuracy: 0.8623 - val_loss: 0.4361 - val_accuracy: 0.8420\n",
      "Epoch 62/100\n",
      "112/171 [==================>...........] - ETA: 0s - loss: 0.3798 - accuracy: 0.8622Restoring model weights from the end of the best epoch.\n",
      "171/171 [==============================] - 0s 946us/step - loss: 0.3851 - accuracy: 0.8567 - val_loss: 0.4588 - val_accuracy: 0.8360\n",
      "Epoch 00062: early stopping\n",
      "Test Accuracy: 85.00000238418579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "# Define the word_index\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Clean the sentences\n",
    "Xtrain = clean_doc(train_x, word_index)\n",
    "Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "# print(Xtrain[0:2])\n",
    "\n",
    "# Encode the sentences into word embedding average representation\n",
    "Xtrain = encoded_sentences(Xtrain)\n",
    "Xtest = encoded_sentences(Xtest)\n",
    "\n",
    "# Define the input shape\n",
    "model = define_model(Xtrain.shape[1])\n",
    "\n",
    "# Train the model\n",
    "model.fit(Xtrain, train_y, batch_size=32, epochs=100, verbose=1, \n",
    "          callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "print('Test Accuracy: {}'.format(acc*100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.00000238418579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "print('Test Accuracy: {}'.format(acc*100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_2(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=6, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 30,706\n",
      "Trainable params: 30,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = define_model_2(300)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=20, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4379 - accuracy: 0.4430 - val_loss: 1.0308 - val_accuracy: 0.6200\n",
      "Epoch 2/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 1.0782 - accuracy: 0.6090 - val_loss: 0.7971 - val_accuracy: 0.7100\n",
      "Epoch 3/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.9198 - accuracy: 0.6581 - val_loss: 0.6736 - val_accuracy: 0.7520\n",
      "Epoch 4/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.8315 - accuracy: 0.6917 - val_loss: 0.6239 - val_accuracy: 0.7840\n",
      "Epoch 5/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.7961 - accuracy: 0.7074 - val_loss: 0.5680 - val_accuracy: 0.8220\n",
      "Epoch 6/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.7296 - val_loss: 0.5604 - val_accuracy: 0.8200\n",
      "Epoch 7/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.7430 - val_loss: 0.5458 - val_accuracy: 0.8060\n",
      "Epoch 8/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.7489 - val_loss: 0.5277 - val_accuracy: 0.8260\n",
      "Epoch 9/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.7621 - val_loss: 0.5161 - val_accuracy: 0.8140\n",
      "Epoch 10/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.7680 - val_loss: 0.5087 - val_accuracy: 0.8320\n",
      "Epoch 11/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.7696 - val_loss: 0.5438 - val_accuracy: 0.8080\n",
      "Epoch 12/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6099 - accuracy: 0.7819 - val_loss: 0.4813 - val_accuracy: 0.8280\n",
      "Epoch 13/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.7793 - val_loss: 0.4924 - val_accuracy: 0.8280\n",
      "Epoch 14/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5824 - accuracy: 0.7848 - val_loss: 0.5031 - val_accuracy: 0.8240\n",
      "Epoch 15/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7962 - val_loss: 0.4501 - val_accuracy: 0.8520\n",
      "Epoch 16/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7975 - val_loss: 0.4741 - val_accuracy: 0.8240\n",
      "Epoch 17/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.8037 - val_loss: 0.4662 - val_accuracy: 0.8320\n",
      "Epoch 18/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.8041 - val_loss: 0.4716 - val_accuracy: 0.8280\n",
      "Epoch 19/100\n",
      "171/171 [==============================] - 0s 984us/step - loss: 0.5254 - accuracy: 0.8043 - val_loss: 0.4560 - val_accuracy: 0.8320\n",
      "Epoch 20/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.8136 - val_loss: 0.4633 - val_accuracy: 0.8300\n",
      "Epoch 21/100\n",
      "171/171 [==============================] - 0s 980us/step - loss: 0.5096 - accuracy: 0.8142 - val_loss: 0.4554 - val_accuracy: 0.8440\n",
      "Epoch 22/100\n",
      "171/171 [==============================] - 0s 996us/step - loss: 0.4928 - accuracy: 0.8223 - val_loss: 0.4425 - val_accuracy: 0.8420\n",
      "Epoch 23/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8225 - val_loss: 0.4557 - val_accuracy: 0.8300\n",
      "Epoch 24/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.8314 - val_loss: 0.4379 - val_accuracy: 0.8440\n",
      "Epoch 25/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.8364 - val_loss: 0.4391 - val_accuracy: 0.8500\n",
      "Epoch 26/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.8276 - val_loss: 0.4534 - val_accuracy: 0.8340\n",
      "Epoch 27/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.8402 - val_loss: 0.4295 - val_accuracy: 0.8480\n",
      "Epoch 28/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.8430 - val_loss: 0.4461 - val_accuracy: 0.8380\n",
      "Epoch 29/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8439 - val_loss: 0.4417 - val_accuracy: 0.8360\n",
      "Epoch 30/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8470 - val_loss: 0.4469 - val_accuracy: 0.8340\n",
      "Epoch 31/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8470 - val_loss: 0.4309 - val_accuracy: 0.8540\n",
      "Epoch 32/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8573 - val_loss: 0.4370 - val_accuracy: 0.8440\n",
      "Epoch 33/100\n",
      "171/171 [==============================] - 0s 984us/step - loss: 0.3999 - accuracy: 0.8606 - val_loss: 0.4466 - val_accuracy: 0.8420\n",
      "Epoch 34/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 0.8619 - val_loss: 0.4473 - val_accuracy: 0.8400\n",
      "Epoch 35/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.8623 - val_loss: 0.4425 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8654 - val_loss: 0.4456 - val_accuracy: 0.8440\n",
      "Epoch 37/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8714 - val_loss: 0.4258 - val_accuracy: 0.8460\n",
      "Epoch 38/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8683 - val_loss: 0.4370 - val_accuracy: 0.8380\n",
      "Epoch 39/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8709 - val_loss: 0.4504 - val_accuracy: 0.8380\n",
      "Epoch 40/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8714 - val_loss: 0.4350 - val_accuracy: 0.8440\n",
      "Epoch 41/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8769 - val_loss: 0.4422 - val_accuracy: 0.8420\n",
      "Epoch 42/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8762 - val_loss: 0.4639 - val_accuracy: 0.8400\n",
      "Epoch 43/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8821 - val_loss: 0.4424 - val_accuracy: 0.8400\n",
      "Epoch 44/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8885 - val_loss: 0.4713 - val_accuracy: 0.8340\n",
      "Epoch 45/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8879 - val_loss: 0.4690 - val_accuracy: 0.8380\n",
      "Epoch 46/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8879 - val_loss: 0.4480 - val_accuracy: 0.8400\n",
      "Epoch 47/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8910 - val_loss: 0.4345 - val_accuracy: 0.8460\n",
      "Epoch 48/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8942 - val_loss: 0.4631 - val_accuracy: 0.8440\n",
      "Epoch 49/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8914 - val_loss: 0.4355 - val_accuracy: 0.8560\n",
      "Epoch 50/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8975 - val_loss: 0.4324 - val_accuracy: 0.8500\n",
      "Epoch 51/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8988 - val_loss: 0.4396 - val_accuracy: 0.8540\n",
      "Epoch 52/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.9011 - val_loss: 0.4596 - val_accuracy: 0.8360\n",
      "Epoch 53/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.9008 - val_loss: 0.4414 - val_accuracy: 0.8540\n",
      "Epoch 54/100\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.9032 - val_loss: 0.4421 - val_accuracy: 0.8500\n",
      "Epoch 55/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.9022 - val_loss: 0.4392 - val_accuracy: 0.8420\n",
      "Epoch 56/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9076 - val_loss: 0.4484 - val_accuracy: 0.8480\n",
      "Epoch 57/100\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.9052 - val_loss: 0.4441 - val_accuracy: 0.8480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.9079 - val_loss: 0.4545 - val_accuracy: 0.8460\n",
      "Epoch 59/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.9171 - val_loss: 0.4535 - val_accuracy: 0.8500\n",
      "Epoch 60/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.9162 - val_loss: 0.4748 - val_accuracy: 0.8480\n",
      "Epoch 61/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9142 - val_loss: 0.4769 - val_accuracy: 0.8480\n",
      "Epoch 62/100\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.9123 - val_loss: 0.4566 - val_accuracy: 0.8460\n",
      "Epoch 63/100\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.9131 - val_loss: 0.4473 - val_accuracy: 0.8500\n",
      "Epoch 64/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9175 - val_loss: 0.4548 - val_accuracy: 0.8560\n",
      "Epoch 65/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9175 - val_loss: 0.4712 - val_accuracy: 0.8520\n",
      "Epoch 66/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9202 - val_loss: 0.4639 - val_accuracy: 0.8480\n",
      "Epoch 67/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9230 - val_loss: 0.4692 - val_accuracy: 0.8440\n",
      "Epoch 68/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9197 - val_loss: 0.4821 - val_accuracy: 0.8460\n",
      "Epoch 69/100\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 0.2173 - accuracy: 0.9327Restoring model weights from the end of the best epoch.\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9321 - val_loss: 0.4795 - val_accuracy: 0.8500\n",
      "Epoch 00069: early stopping\n",
      "Test Accuracy: 85.6000006198883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "# Define the word_index\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Clean the sentences\n",
    "Xtrain = clean_doc(train_x, word_index)\n",
    "Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "# print(Xtrain[0:2])\n",
    "\n",
    "# Encode the sentences into word embedding average representation\n",
    "Xtrain = encoded_sentences(Xtrain)\n",
    "Xtest = encoded_sentences(Xtest)\n",
    "\n",
    "# Define the input shape\n",
    "model = define_model_2(Xtrain.shape[1])\n",
    "\n",
    "# Train the model\n",
    "model.fit(Xtrain, train_y, batch_size=32, epochs=100, verbose=1, \n",
    "          callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "print('Test Accuracy: {}'.format(acc*100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.6000006198883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "print('Test Accuracy: {}'.format(acc*100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_3(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=50, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=6, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 35,456\n",
      "Trainable params: 35,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = define_model_3(300)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=20, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5603 - accuracy: 0.3452 - val_loss: 1.0831 - val_accuracy: 0.6300\n",
      "Epoch 2/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 1.1710 - accuracy: 0.5541 - val_loss: 0.7979 - val_accuracy: 0.7380\n",
      "Epoch 3/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.9900 - accuracy: 0.6278 - val_loss: 0.6759 - val_accuracy: 0.7700\n",
      "Epoch 4/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.9056 - accuracy: 0.6708 - val_loss: 0.6256 - val_accuracy: 0.7760\n",
      "Epoch 5/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.8433 - accuracy: 0.6928 - val_loss: 0.5782 - val_accuracy: 0.8140\n",
      "Epoch 6/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.7953 - accuracy: 0.7076 - val_loss: 0.5362 - val_accuracy: 0.8200\n",
      "Epoch 7/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.7591 - accuracy: 0.7219 - val_loss: 0.5136 - val_accuracy: 0.8220\n",
      "Epoch 8/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7264 - accuracy: 0.7351 - val_loss: 0.5164 - val_accuracy: 0.8180\n",
      "Epoch 9/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.7471 - val_loss: 0.5188 - val_accuracy: 0.8040\n",
      "Epoch 10/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.7590 - val_loss: 0.4872 - val_accuracy: 0.8340\n",
      "Epoch 11/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.7625 - val_loss: 0.5061 - val_accuracy: 0.8220\n",
      "Epoch 12/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.7737 - val_loss: 0.5101 - val_accuracy: 0.8220\n",
      "Epoch 13/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.6131 - accuracy: 0.7850 - val_loss: 0.4752 - val_accuracy: 0.8280\n",
      "Epoch 14/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.7867 - val_loss: 0.4881 - val_accuracy: 0.8360\n",
      "Epoch 15/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.7962 - val_loss: 0.4631 - val_accuracy: 0.8440\n",
      "Epoch 16/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.8030 - val_loss: 0.4826 - val_accuracy: 0.8320\n",
      "Epoch 17/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.8092 - val_loss: 0.4555 - val_accuracy: 0.8420\n",
      "Epoch 18/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.8136 - val_loss: 0.4505 - val_accuracy: 0.8520\n",
      "Epoch 19/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.8190 - val_loss: 0.4434 - val_accuracy: 0.8480\n",
      "Epoch 20/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8208 - val_loss: 0.4477 - val_accuracy: 0.8580\n",
      "Epoch 21/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8215 - val_loss: 0.4688 - val_accuracy: 0.8380\n",
      "Epoch 22/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.8281 - val_loss: 0.4509 - val_accuracy: 0.8520\n",
      "Epoch 23/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.8355 - val_loss: 0.4647 - val_accuracy: 0.8360\n",
      "Epoch 24/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.8457 - val_loss: 0.4975 - val_accuracy: 0.8320\n",
      "Epoch 25/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.8492 - val_loss: 0.4802 - val_accuracy: 0.8300\n",
      "Epoch 26/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8474 - val_loss: 0.4530 - val_accuracy: 0.8480\n",
      "Epoch 27/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8545 - val_loss: 0.4529 - val_accuracy: 0.8520\n",
      "Epoch 28/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8562 - val_loss: 0.4678 - val_accuracy: 0.8440\n",
      "Epoch 29/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3842 - accuracy: 0.8657 - val_loss: 0.4851 - val_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8595 - val_loss: 0.4541 - val_accuracy: 0.8480\n",
      "Epoch 31/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8749 - val_loss: 0.4647 - val_accuracy: 0.8480\n",
      "Epoch 32/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8698 - val_loss: 0.4166 - val_accuracy: 0.8520\n",
      "Epoch 33/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8773 - val_loss: 0.5001 - val_accuracy: 0.8360\n",
      "Epoch 34/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8806 - val_loss: 0.4974 - val_accuracy: 0.8380\n",
      "Epoch 35/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8810 - val_loss: 0.4924 - val_accuracy: 0.8440\n",
      "Epoch 36/100\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8841 - val_loss: 0.4573 - val_accuracy: 0.8540\n",
      "Epoch 37/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8764 - val_loss: 0.4800 - val_accuracy: 0.8460\n",
      "Epoch 38/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8931 - val_loss: 0.5067 - val_accuracy: 0.8400\n",
      "Epoch 39/100\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8866 - val_loss: 0.5074 - val_accuracy: 0.8440\n",
      "Epoch 40/100\n",
      "169/171 [============================>.] - ETA: 0s - loss: 0.3044 - accuracy: 0.8929Restoring model weights from the end of the best epoch.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8927 - val_loss: 0.4974 - val_accuracy: 0.8500\n",
      "Epoch 00040: early stopping\n",
      "Test Accuracy: 85.79999804496765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(corpus[corpus.split=='train'].sentence)\n",
    "train_y = np.array(corpus[corpus.split=='train'].label)\n",
    "test_x = list(corpus[corpus.split=='test'].sentence)\n",
    "test_y = np.array(corpus[corpus.split=='test'].label)\n",
    "\n",
    "# Define the word_index\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Clean the sentences\n",
    "Xtrain = clean_doc(train_x, word_index)\n",
    "Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "# print(Xtrain[0:2])\n",
    "\n",
    "# Encode the sentences into word embedding average representation\n",
    "Xtrain = encoded_sentences(Xtrain)\n",
    "Xtest = encoded_sentences(Xtest)\n",
    "\n",
    "# Define the input shape\n",
    "model = define_model_3(Xtrain.shape[1])\n",
    "\n",
    "# Train the model\n",
    "model.fit(Xtrain, train_y, batch_size=32, epochs=100, verbose=1, \n",
    "          callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "print('Test Accuracy: {}'.format(acc*100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.79999804496765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "print('Test Accuracy: {}'.format(acc*100))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
