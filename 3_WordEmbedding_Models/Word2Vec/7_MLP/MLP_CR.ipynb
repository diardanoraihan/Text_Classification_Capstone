{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classification with CR Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using Multi Layer Perceptron on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3775, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weaknesses are minor the feel and layout of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many of our disney movies do n 't play on this...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player has a problem with dual layer dvd 's su...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i know the saying is you get what you pay for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will never purchase apex again .</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>so far , the anti spam feature seems to be ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>i did not have any of the installation problem...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>their products have been great and have saved ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3775 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     weaknesses are minor the feel and layout of th...      0  train\n",
       "1     many of our disney movies do n 't play on this...      0  train\n",
       "2     player has a problem with dual layer dvd 's su...      0  train\n",
       "3     i know the saying is you get what you pay for ...      0  train\n",
       "4                      will never purchase apex again .      0  train\n",
       "...                                                 ...    ...    ...\n",
       "3770  so far , the anti spam feature seems to be ver...      1  train\n",
       "3771  i downloaded a trial version of computer assoc...      1  train\n",
       "3772  i did not have any of the installation problem...      1  train\n",
       "3773  their products have been great and have saved ...      1  train\n",
       "3774                                                         1  train\n",
       "\n",
       "[3775 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/CR/CR.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3775 entries, 0 to 3774\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  3775 non-null   object\n",
      " 1   label     3775 non-null   int32 \n",
      " 2   split     3775 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 73.9+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2407</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          1368   1368\n",
       "1          2407   2407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weaknesses are minor the feel and layout of the remote control are only so so . it does n 't show the complete file names of mp3s with really long names . you must cycle through every zoom setting ( 2x , 3x , 4x , 1 2x , etc . ) before getting back to normal size sorry if i 'm just ignorant of a way to get back to 1x quickly .\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Word2Vec Static\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Word Embedding: Word2Vec\n",
    "\n",
    "__1. Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5046 words present from 5336 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "oov_tok = '<UNK>'\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `clean_doc` function\n",
    "__2. Define a function to clean the document called __`clean_doc()`____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(sentences, word_index):\n",
    "    clean_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower().split()\n",
    "        clean_word = []\n",
    "        for word in sentence:\n",
    "            if word in word_index:\n",
    "                clean_word.append(word)\n",
    "        clean_sentence = ' '.join(clean_word)\n",
    "        clean_sentences.append(clean_sentence)\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"weaknesses are minor the feel and layout of the remote control are only so so it does n 't show the complete file names of mp3s with really long names you must cycle through every zoom setting 2x 3x 4x 1 2x etc before getting back to normal size sorry if i 'm just ignorant of a way to get back to 1x quickly\",\n",
       " \"many of our disney movies do n 't play on this dvd player\",\n",
       " \"player has a problem with dual layer dvd 's such as alias season 1 and season 2\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences = clean_doc(sentences, word_index)\n",
    "clean_sentences[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `sentence_to_avg` function\n",
    "__3. Define a `sentence_to_avg` function__\n",
    "\n",
    "We will use this function to calculate the mean of word embedding representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Split sentence into list of lower case words (≈ 1 line)\n",
    "    words = (sentence.lower()).split()\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros(word2vec.word_vec('i').shape)\n",
    "    \n",
    "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in word_to_vec_map:\n",
    "            total += word_to_vec_map.word_vec(w)\n",
    "            count += 1\n",
    "            \n",
    "    if count!= 0:\n",
    "        avg = total/count\n",
    "    else:\n",
    "        avg\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.22558594\n",
      "-0.16699219\n",
      "0.11376953\n",
      "the mean of word embedding is:  -0.09293619791666667\n"
     ]
    }
   ],
   "source": [
    "i = word2vec.word_vec('i')[0]\n",
    "print(word2vec.word_vec('i')[0])\n",
    "j = word2vec.word_vec('am')[0]\n",
    "print(word2vec.word_vec('am')[0])\n",
    "k = word2vec.word_vec('handsome')[0]\n",
    "print(word2vec.word_vec('handsome')[0])\n",
    "mean = (i+j+k)/3\n",
    "print('the mean of word embedding is: ', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0929362 ,  0.03125   , -0.03914388,  0.09879557,  0.07088598,\n",
       "        0.03092448, -0.00651042, -0.04437256,  0.08068848,  0.07242838,\n",
       "        0.00160726, -0.10530599, -0.07389323, -0.08854166,  0.00565592,\n",
       "        0.15136719, -0.0460612 ,  0.19482422,  0.1101888 ,  0.05924479,\n",
       "       -0.18457031,  0.00716146,  0.16153972,  0.02437337, -0.01578776,\n",
       "        0.06119792, -0.25048828,  0.02799479,  0.0853475 , -0.14029948,\n",
       "        0.13688152, -0.01350911, -0.05493164, -0.01090495,  0.03352864,\n",
       "        0.09635416, -0.04239909,  0.00777181, -0.1438802 ,  0.06510416,\n",
       "        0.14560954, -0.11295573,  0.25520834,  0.08833822,  0.14339192,\n",
       "        0.037028  , -0.02832031, -0.00139872,  0.00309245, -0.17871094,\n",
       "        0.06852213,  0.07910156,  0.09513346,  0.11425781, -0.00488281,\n",
       "        0.11051432, -0.01139323, -0.08479818, -0.09277344, -0.03263346,\n",
       "       -0.00374349,  0.07977295, -0.26416016, -0.05135091,  0.06111654,\n",
       "       -0.06933594, -0.06486002,  0.18766277, -0.04826609,  0.03304036,\n",
       "        0.24267578,  0.11425781,  0.02310689,  0.06697591, -0.19010417,\n",
       "        0.03230794,  0.00317383, -0.03739421,  0.12434896,  0.1574707 ,\n",
       "       -0.05745443,  0.015625  ,  0.01456706, -0.05794271, -0.0549113 ,\n",
       "        0.0398763 , -0.01517741,  0.11263021, -0.03271484,  0.06758627,\n",
       "       -0.09594727,  0.06559245,  0.00217692,  0.03627523, -0.03776042,\n",
       "        0.02945963, -0.05960592, -0.02514648,  0.07128906, -0.04410807,\n",
       "       -0.21533203, -0.02174886, -0.05029297,  0.04264323,  0.08194987,\n",
       "        0.05502828,  0.09375   , -0.02050781,  0.04243978, -0.1439616 ,\n",
       "        0.        , -0.17805989,  0.0822347 ,  0.00140381,  0.17220052,\n",
       "       -0.08251953,  0.00450643, -0.24837239,  0.14001465,  0.01749674,\n",
       "        0.24576823, -0.06986491, -0.04370117,  0.01497396, -0.01534017,\n",
       "        0.09863281, -0.12027995,  0.14615886,  0.19580078,  0.08813477,\n",
       "       -0.2861328 , -0.0653483 , -0.03889974, -0.07784017, -0.12190755,\n",
       "       -0.04427083, -0.06233724,  0.08296712,  0.12670898,  0.1593221 ,\n",
       "        0.04296875,  0.08544922, -0.01513672,  0.        , -0.2101237 ,\n",
       "        0.11390177, -0.01127116, -0.06298828,  0.0198822 , -0.03000895,\n",
       "       -0.05118815, -0.00195312, -0.1007487 ,  0.09879557, -0.19702148,\n",
       "       -0.05611674, -0.03466797,  0.13932292, -0.0764974 , -0.00777181,\n",
       "        0.05948893,  0.11360677,  0.01757812,  0.07926432, -0.0104777 ,\n",
       "       -0.16145833,  0.17708333,  0.13507843, -0.06380209,  0.10839844,\n",
       "       -0.21500652, -0.0933431 ,  0.05853271, -0.14601643, -0.0369873 ,\n",
       "        0.02945963,  0.2747396 , -0.07006454,  0.06966146, -0.17203777,\n",
       "       -0.02294922, -0.09220377, -0.01790492, -0.0111084 , -0.03776042,\n",
       "        0.03540039, -0.03483073,  0.0764974 ,  0.07096354, -0.13916016,\n",
       "       -0.01989746,  0.06176758, -0.11336263, -0.03279241,  0.08687337,\n",
       "        0.15901692, -0.07185873,  0.02547201, -0.03220622, -0.125     ,\n",
       "       -0.12727864,  0.02563477, -0.06311035, -0.16959636, -0.10058594,\n",
       "       -0.05464681, -0.09391276,  0.06502279, -0.06184896,  0.14835612,\n",
       "       -0.1031901 ,  0.07779948, -0.06420898, -0.0892334 , -0.20214844,\n",
       "        0.13671875,  0.11507162, -0.00145467, -0.23079427, -0.04801432,\n",
       "       -0.06262207,  0.07454427,  0.0298055 , -0.01489258,  0.08854166,\n",
       "       -0.1608073 , -0.00372314, -0.056722  , -0.06841787, -0.16031902,\n",
       "        0.1538086 , -0.03597005, -0.09985352, -0.03483073,  0.07324219,\n",
       "        0.03672282,  0.03737386,  0.06705729,  0.10375977,  0.04850261,\n",
       "        0.20996094,  0.06673177,  0.03833008,  0.06363932, -0.18758138,\n",
       "       -0.10904948, -0.02693685,  0.02254232, -0.08405808,  0.02848307,\n",
       "        0.17675781,  0.01188151,  0.08610026,  0.18359375,  0.0764974 ,\n",
       "        0.03463237,  0.08015951,  0.00455729, -0.15309651,  0.00195312,\n",
       "        0.0965983 , -0.18180339, -0.02457682, -0.01757812, -0.08410645,\n",
       "        0.20092773, -0.12624104, -0.09566244, -0.03291829, -0.04532878,\n",
       "        0.04199219, -0.01635742,  0.04329427,  0.06469727,  0.04390462,\n",
       "        0.03625488, -0.04744466, -0.14420573, -0.17626953,  0.18603516,\n",
       "        0.01155599,  0.06009929, -0.02880859,  0.06738281,  0.0949707 ,\n",
       "        0.00325521, -0.07470703, -0.18782552, -0.00447591,  0.06038411,\n",
       "        0.0456543 ,  0.10611979, -0.11393229, -0.05623372, -0.03450521,\n",
       "        0.02193197, -0.12263998, -0.08158366, -0.0332845 ,  0.09596761],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the functions used in a sentence\n",
    "mysentence = 'I am handsome'\n",
    "sentence_to_avg(mysentence, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Sentence into Word2Vec Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_sentences(sentences):\n",
    "\n",
    "    encoded_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        encoded_sentence = sentence_to_avg(sentence, word2vec)\n",
    "        encoded_sentences.append(encoded_sentence)\n",
    "\n",
    "    encoded_sentences = np.array(encoded_sentences)\n",
    "    return encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3775, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.02931269,  0.04064355,  0.00335943, ..., -0.05255696,\n",
       "        -0.00678974, -0.03428983],\n",
       "       [ 0.02625621,  0.07036244, -0.00320712, ..., -0.0249717 ,\n",
       "         0.02348744, -0.04393421],\n",
       "       [ 0.0471889 ,  0.04338728, -0.02501352, ..., -0.07487269,\n",
       "         0.00302996, -0.02290562],\n",
       "       ...,\n",
       "       [-0.01438395,  0.04383342,  0.0245463 , ..., -0.08561961,\n",
       "         0.0373319 , -0.09303284],\n",
       "       [-0.01439794,  0.05486043, -0.01898448, ..., -0.08718872,\n",
       "         0.02372233, -0.02985636],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = encoded_sentences(clean_sentences)\n",
    "print(embedded_sentences.shape)\n",
    "embedded_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=50, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                15050     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 15,101\n",
      "Trainable params: 15,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model(300)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "'''\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.6287 - accuracy: 0.6394 - val_loss: 0.5811 - val_accuracy: 0.6640\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7103 - val_loss: 0.5297 - val_accuracy: 0.7196\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7580 - val_loss: 0.5057 - val_accuracy: 0.7381\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7730 - val_loss: 0.4921 - val_accuracy: 0.7407\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7801 - val_loss: 0.4891 - val_accuracy: 0.7646\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7851 - val_loss: 0.4761 - val_accuracy: 0.7751\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7963 - val_loss: 0.4764 - val_accuracy: 0.7672\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8075 - val_loss: 0.4677 - val_accuracy: 0.7725\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8063 - val_loss: 0.4718 - val_accuracy: 0.7725\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8063 - val_loss: 0.4710 - val_accuracy: 0.7725\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8095 - val_loss: 0.4624 - val_accuracy: 0.7831\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8151 - val_loss: 0.4617 - val_accuracy: 0.7751\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8166 - val_loss: 0.4620 - val_accuracy: 0.7725\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8195 - val_loss: 0.4627 - val_accuracy: 0.7725\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8213 - val_loss: 0.4629 - val_accuracy: 0.7698\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8231 - val_loss: 0.4617 - val_accuracy: 0.7804\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8216 - val_loss: 0.4583 - val_accuracy: 0.7778\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8169 - val_loss: 0.4586 - val_accuracy: 0.7751\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8296 - val_loss: 0.4587 - val_accuracy: 0.7725\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8204 - val_loss: 0.4635 - val_accuracy: 0.7778\n",
      "Epoch 21/40\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.3741 - accuracy: 0.8287Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8287 - val_loss: 0.4551 - val_accuracy: 0.7804\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 78.30687761306763\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.6245 - accuracy: 0.6412 - val_loss: 0.6000 - val_accuracy: 0.6561\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7109 - val_loss: 0.5535 - val_accuracy: 0.7011\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7533 - val_loss: 0.5050 - val_accuracy: 0.7328\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7769 - val_loss: 0.4932 - val_accuracy: 0.7460\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7904 - val_loss: 0.4782 - val_accuracy: 0.7513\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7910 - val_loss: 0.4752 - val_accuracy: 0.7593\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7966 - val_loss: 0.4677 - val_accuracy: 0.7619\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8072 - val_loss: 0.4601 - val_accuracy: 0.7778\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8054 - val_loss: 0.4551 - val_accuracy: 0.7910\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8116 - val_loss: 0.4571 - val_accuracy: 0.7857\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8154 - val_loss: 0.4594 - val_accuracy: 0.7831\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8190 - val_loss: 0.4572 - val_accuracy: 0.7857\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8125 - val_loss: 0.4498 - val_accuracy: 0.7857\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8195 - val_loss: 0.4547 - val_accuracy: 0.7857\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8195 - val_loss: 0.4612 - val_accuracy: 0.7804\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8190 - val_loss: 0.4482 - val_accuracy: 0.7751\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8187 - val_loss: 0.4543 - val_accuracy: 0.7857\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8287 - val_loss: 0.4483 - val_accuracy: 0.7778\n",
      "Epoch 19/40\n",
      " 99/107 [==========================>...] - ETA: 0s - loss: 0.3759 - accuracy: 0.8352Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8337 - val_loss: 0.4498 - val_accuracy: 0.7857\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 79.10053133964539\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.6294 - accuracy: 0.6353 - val_loss: 0.5924 - val_accuracy: 0.6376\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.6994 - val_loss: 0.5306 - val_accuracy: 0.7090\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7577 - val_loss: 0.4932 - val_accuracy: 0.7646\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7669 - val_loss: 0.4736 - val_accuracy: 0.7751\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7813 - val_loss: 0.4636 - val_accuracy: 0.7963\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7836 - val_loss: 0.4612 - val_accuracy: 0.7672\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7963 - val_loss: 0.4518 - val_accuracy: 0.7857\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7992 - val_loss: 0.4549 - val_accuracy: 0.7831\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8098 - val_loss: 0.4504 - val_accuracy: 0.7857\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8131 - val_loss: 0.4455 - val_accuracy: 0.7857\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8063 - val_loss: 0.4413 - val_accuracy: 0.7831\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8113 - val_loss: 0.4438 - val_accuracy: 0.7963\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8187 - val_loss: 0.4391 - val_accuracy: 0.7884\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8222 - val_loss: 0.4500 - val_accuracy: 0.7884\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.3905 - accuracy: 0.8243Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8228 - val_loss: 0.4401 - val_accuracy: 0.7937\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.6356 - accuracy: 0.6294 - val_loss: 0.5909 - val_accuracy: 0.6508\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7027 - val_loss: 0.5403 - val_accuracy: 0.7143\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7536 - val_loss: 0.5139 - val_accuracy: 0.7540\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7739 - val_loss: 0.5024 - val_accuracy: 0.7698\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7827 - val_loss: 0.4942 - val_accuracy: 0.7725\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7957 - val_loss: 0.4894 - val_accuracy: 0.7672\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7989 - val_loss: 0.4841 - val_accuracy: 0.7540\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8063 - val_loss: 0.4787 - val_accuracy: 0.7778\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8092 - val_loss: 0.4777 - val_accuracy: 0.7725\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8142 - val_loss: 0.4827 - val_accuracy: 0.7487\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8084 - val_loss: 0.4756 - val_accuracy: 0.7725\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8157 - val_loss: 0.4772 - val_accuracy: 0.7831\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8198 - val_loss: 0.4786 - val_accuracy: 0.7672\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8228 - val_loss: 0.4753 - val_accuracy: 0.7804\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8243 - val_loss: 0.4753 - val_accuracy: 0.7725\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8225 - val_loss: 0.4768 - val_accuracy: 0.7698\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8290 - val_loss: 0.4771 - val_accuracy: 0.7672\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8278 - val_loss: 0.4782 - val_accuracy: 0.7804\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8307 - val_loss: 0.4731 - val_accuracy: 0.7751\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8349 - val_loss: 0.4766 - val_accuracy: 0.7751\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8296 - val_loss: 0.4732 - val_accuracy: 0.7725\n",
      "Epoch 22/40\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.3716 - accuracy: 0.8317Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8316 - val_loss: 0.4770 - val_accuracy: 0.7725\n",
      "Epoch 00022: early stopping\n",
      "Test Accuracy: 78.30687761306763\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.6356 - accuracy: 0.6309 - val_loss: 0.5609 - val_accuracy: 0.6905\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7109 - val_loss: 0.4993 - val_accuracy: 0.7725\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7548 - val_loss: 0.4738 - val_accuracy: 0.7884\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7648 - val_loss: 0.4367 - val_accuracy: 0.7937\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7816 - val_loss: 0.4224 - val_accuracy: 0.7963\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7854 - val_loss: 0.4074 - val_accuracy: 0.8069\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7931 - val_loss: 0.3999 - val_accuracy: 0.8042\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7995 - val_loss: 0.3924 - val_accuracy: 0.8069\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8069 - val_loss: 0.3888 - val_accuracy: 0.8201\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8048 - val_loss: 0.3901 - val_accuracy: 0.8333\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8075 - val_loss: 0.4111 - val_accuracy: 0.8095\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8098 - val_loss: 0.3845 - val_accuracy: 0.8148\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8142 - val_loss: 0.3849 - val_accuracy: 0.8201\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8128 - val_loss: 0.3819 - val_accuracy: 0.8175\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8198 - val_loss: 0.3796 - val_accuracy: 0.8228\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8193 - val_loss: 0.3787 - val_accuracy: 0.8175\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8175 - val_loss: 0.3926 - val_accuracy: 0.8201\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8204 - val_loss: 0.3799 - val_accuracy: 0.8254\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8269 - val_loss: 0.3835 - val_accuracy: 0.8175\n",
      "Epoch 20/40\n",
      "103/107 [===========================>..] - ETA: 0s - loss: 0.3854 - accuracy: 0.8255Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8234 - val_loss: 0.3799 - val_accuracy: 0.8201\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 83.33333134651184\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.6339 - accuracy: 0.6398 - val_loss: 0.6307 - val_accuracy: 0.5942\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.6881 - val_loss: 0.5666 - val_accuracy: 0.7056\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7448 - val_loss: 0.5471 - val_accuracy: 0.7109\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7640 - val_loss: 0.5106 - val_accuracy: 0.7719\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7763 - val_loss: 0.4935 - val_accuracy: 0.7666\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7884 - val_loss: 0.5097 - val_accuracy: 0.7533\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7952 - val_loss: 0.4787 - val_accuracy: 0.7692\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7911 - val_loss: 0.4861 - val_accuracy: 0.7798\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8037 - val_loss: 0.4753 - val_accuracy: 0.7772\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8081 - val_loss: 0.4693 - val_accuracy: 0.7692\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8190 - val_loss: 0.4655 - val_accuracy: 0.7692\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8111 - val_loss: 0.4602 - val_accuracy: 0.7719\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8152 - val_loss: 0.4690 - val_accuracy: 0.7692\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8184 - val_loss: 0.4564 - val_accuracy: 0.7745\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8237 - val_loss: 0.4726 - val_accuracy: 0.7772\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8214 - val_loss: 0.4563 - val_accuracy: 0.7905\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8270 - val_loss: 0.4604 - val_accuracy: 0.7825\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8246 - val_loss: 0.4595 - val_accuracy: 0.7851\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8284 - val_loss: 0.4569 - val_accuracy: 0.7931\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8290 - val_loss: 0.4523 - val_accuracy: 0.7798\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8299 - val_loss: 0.4635 - val_accuracy: 0.7798\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8384 - val_loss: 0.4634 - val_accuracy: 0.7719\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8361 - val_loss: 0.4527 - val_accuracy: 0.7798\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8325 - val_loss: 0.4510 - val_accuracy: 0.7825\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8411 - val_loss: 0.4607 - val_accuracy: 0.7878\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8328 - val_loss: 0.4573 - val_accuracy: 0.7825\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8376 - val_loss: 0.4524 - val_accuracy: 0.7905\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.8428 - val_loss: 0.4524 - val_accuracy: 0.7851\n",
      "Epoch 29/40\n",
      " 92/107 [========================>.....] - ETA: 0s - loss: 0.3580 - accuracy: 0.8434Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8414 - val_loss: 0.4504 - val_accuracy: 0.7878\n",
      "Epoch 00029: early stopping\n",
      "Test Accuracy: 79.31034564971924\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 6s 52ms/step - loss: 0.6350 - accuracy: 0.6392 - val_loss: 0.5809 - val_accuracy: 0.6393\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.6963 - val_loss: 0.5171 - val_accuracy: 0.7374\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7448 - val_loss: 0.4819 - val_accuracy: 0.7719\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4874 - accuracy: 0.7749 - val_loss: 0.4643 - val_accuracy: 0.7745\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7749 - val_loss: 0.4499 - val_accuracy: 0.7851\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7887 - val_loss: 0.4389 - val_accuracy: 0.7905\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7984 - val_loss: 0.4412 - val_accuracy: 0.7878\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4411 - accuracy: 0.7984 - val_loss: 0.4291 - val_accuracy: 0.7931\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4253 - accuracy: 0.8061 - val_loss: 0.4226 - val_accuracy: 0.7905\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4261 - accuracy: 0.8108 - val_loss: 0.4215 - val_accuracy: 0.7958\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8064 - val_loss: 0.4204 - val_accuracy: 0.7878\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8084 - val_loss: 0.4156 - val_accuracy: 0.7878\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8099 - val_loss: 0.4115 - val_accuracy: 0.8090\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8167 - val_loss: 0.4120 - val_accuracy: 0.7878\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8161 - val_loss: 0.4095 - val_accuracy: 0.7931\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8172 - val_loss: 0.4051 - val_accuracy: 0.7984\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8181 - val_loss: 0.4043 - val_accuracy: 0.7931\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8217 - val_loss: 0.4083 - val_accuracy: 0.7905\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8190 - val_loss: 0.4031 - val_accuracy: 0.7958\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8270 - val_loss: 0.4030 - val_accuracy: 0.7958\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8273 - val_loss: 0.4000 - val_accuracy: 0.8143\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8305 - val_loss: 0.4007 - val_accuracy: 0.7958\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8275 - val_loss: 0.3991 - val_accuracy: 0.8037\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8352 - val_loss: 0.4003 - val_accuracy: 0.8011\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8314 - val_loss: 0.3972 - val_accuracy: 0.8037\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8331 - val_loss: 0.3993 - val_accuracy: 0.8037\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8343 - val_loss: 0.3961 - val_accuracy: 0.8117\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8364 - val_loss: 0.4000 - val_accuracy: 0.8143\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8308 - val_loss: 0.3957 - val_accuracy: 0.8143\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8376 - val_loss: 0.3981 - val_accuracy: 0.8117\n",
      "Epoch 31/40\n",
      " 92/107 [========================>.....] - ETA: 0s - loss: 0.3615 - accuracy: 0.8329Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8331 - val_loss: 0.3958 - val_accuracy: 0.8117\n",
      "Epoch 00031: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.6281 - accuracy: 0.6442 - val_loss: 0.5799 - val_accuracy: 0.6684\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7139 - val_loss: 0.5239 - val_accuracy: 0.7374\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7451 - val_loss: 0.4961 - val_accuracy: 0.7507\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7722 - val_loss: 0.4787 - val_accuracy: 0.7719\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.4668 - val_accuracy: 0.7825\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7928 - val_loss: 0.4574 - val_accuracy: 0.7931\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.4638 - val_accuracy: 0.7586\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8067 - val_loss: 0.4526 - val_accuracy: 0.7798\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8072 - val_loss: 0.4480 - val_accuracy: 0.7825\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8081 - val_loss: 0.4432 - val_accuracy: 0.7825\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8078 - val_loss: 0.4494 - val_accuracy: 0.7851\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8043 - val_loss: 0.4440 - val_accuracy: 0.7745\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8146 - val_loss: 0.4418 - val_accuracy: 0.7798\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8167 - val_loss: 0.4433 - val_accuracy: 0.7851\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8231 - val_loss: 0.4485 - val_accuracy: 0.7639\n",
      "Epoch 16/40\n",
      "102/107 [===========================>..] - ETA: 0s - loss: 0.3976 - accuracy: 0.8226Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8222 - val_loss: 0.4482 - val_accuracy: 0.7639\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 79.31034564971924\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.6222 - accuracy: 0.6445 - val_loss: 0.5717 - val_accuracy: 0.6578\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7069 - val_loss: 0.5105 - val_accuracy: 0.7507\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7534 - val_loss: 0.4774 - val_accuracy: 0.7507\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7752 - val_loss: 0.4580 - val_accuracy: 0.7851\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7799 - val_loss: 0.4501 - val_accuracy: 0.7905\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7934 - val_loss: 0.4427 - val_accuracy: 0.7905\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7984 - val_loss: 0.4380 - val_accuracy: 0.7851\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7922 - val_loss: 0.4358 - val_accuracy: 0.8011\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8022 - val_loss: 0.4306 - val_accuracy: 0.8064\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8005 - val_loss: 0.4282 - val_accuracy: 0.8090\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8170 - val_loss: 0.4284 - val_accuracy: 0.7931\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4143 - accuracy: 0.8043 - val_loss: 0.4262 - val_accuracy: 0.7931\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8187 - val_loss: 0.4286 - val_accuracy: 0.7984\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8196 - val_loss: 0.4236 - val_accuracy: 0.8090\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8190 - val_loss: 0.4254 - val_accuracy: 0.7931\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.3975 - accuracy: 0.8093 - val_loss: 0.4231 - val_accuracy: 0.8011\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.3911 - accuracy: 0.8237 - val_loss: 0.4231 - val_accuracy: 0.8037\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.3938 - accuracy: 0.8190 - val_loss: 0.4232 - val_accuracy: 0.8064\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8225 - val_loss: 0.4217 - val_accuracy: 0.8090\n",
      "Epoch 20/40\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.3850 - accuracy: 0.8259Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8267 - val_loss: 0.4281 - val_accuracy: 0.7905\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.6326 - accuracy: 0.6366 - val_loss: 0.5728 - val_accuracy: 0.6737\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7160 - val_loss: 0.5187 - val_accuracy: 0.7560\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7566 - val_loss: 0.4953 - val_accuracy: 0.7984\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7610 - val_loss: 0.4582 - val_accuracy: 0.7958\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7740 - val_loss: 0.4549 - val_accuracy: 0.8090\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7825 - val_loss: 0.4369 - val_accuracy: 0.8037\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7969 - val_loss: 0.4273 - val_accuracy: 0.8064\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7999 - val_loss: 0.4222 - val_accuracy: 0.8011\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8037 - val_loss: 0.4199 - val_accuracy: 0.7984\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8025 - val_loss: 0.4187 - val_accuracy: 0.8037\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8099 - val_loss: 0.4133 - val_accuracy: 0.8064\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8108 - val_loss: 0.4254 - val_accuracy: 0.7984\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4112 - accuracy: 0.8125 - val_loss: 0.4175 - val_accuracy: 0.7984\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8178 - val_loss: 0.4197 - val_accuracy: 0.8037\n",
      "Epoch 15/40\n",
      "104/107 [============================>.] - ETA: 0s - loss: 0.4010 - accuracy: 0.8128Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8128 - val_loss: 0.4088 - val_accuracy: 0.7984\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "\n",
      "\n",
      "        acc1       acc2      acc3       acc4       acc5       acc6      acc7  \\\n",
      "0  78.306878  79.100531  79.62963  78.306878  83.333331  79.310346  81.43236   \n",
      "\n",
      "        acc8       acc9      acc10        AVG  \n",
      "0  79.310346  80.901855  80.901855  80.053401  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Obtain the word to index\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record = record.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.306878</td>\n",
       "      <td>79.100531</td>\n",
       "      <td>79.62963</td>\n",
       "      <td>78.306878</td>\n",
       "      <td>83.333331</td>\n",
       "      <td>79.310346</td>\n",
       "      <td>81.43236</td>\n",
       "      <td>79.310346</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>80.053401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2      acc3       acc4       acc5       acc6      acc7  \\\n",
       "0  78.306878  79.100531  79.62963  78.306878  83.333331  79.310346  81.43236   \n",
       "\n",
       "        acc8       acc9      acc10        AVG  \n",
       "0  79.310346  80.901855  80.901855  80.053401  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record\n",
    "report = report.to_excel('Emb_MLP_CR.xlsx', sheet_name='model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_2(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 30,201\n",
      "Trainable params: 30,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = define_model_2(300)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.6065 - accuracy: 0.6562 - val_loss: 0.5659 - val_accuracy: 0.6534\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7401 - val_loss: 0.5033 - val_accuracy: 0.7354\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7680 - val_loss: 0.4740 - val_accuracy: 0.7725\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7942 - val_loss: 0.4589 - val_accuracy: 0.7566\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7960 - val_loss: 0.4672 - val_accuracy: 0.7593\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.8007 - val_loss: 0.4493 - val_accuracy: 0.7698\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8092 - val_loss: 0.4438 - val_accuracy: 0.7646\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8034 - val_loss: 0.4464 - val_accuracy: 0.7593\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8066 - val_loss: 0.4422 - val_accuracy: 0.7619\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8137 - val_loss: 0.4404 - val_accuracy: 0.7804\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8243 - val_loss: 0.4542 - val_accuracy: 0.7646\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8210 - val_loss: 0.4554 - val_accuracy: 0.7619\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8257 - val_loss: 0.4440 - val_accuracy: 0.7725\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.3828 - accuracy: 0.8281 - val_loss: 0.4431 - val_accuracy: 0.7619\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.3833 - accuracy: 0.8210 - val_loss: 0.4505 - val_accuracy: 0.7646\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8287 - val_loss: 0.4422 - val_accuracy: 0.7804\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.3723 - accuracy: 0.8331 - val_loss: 0.4436 - val_accuracy: 0.7804\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8307 - val_loss: 0.4418 - val_accuracy: 0.7725\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8372 - val_loss: 0.4423 - val_accuracy: 0.7804\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8328 - val_loss: 0.4459 - val_accuracy: 0.7831\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8407 - val_loss: 0.4481 - val_accuracy: 0.7778\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8381 - val_loss: 0.4556 - val_accuracy: 0.7751\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8437 - val_loss: 0.4539 - val_accuracy: 0.7857\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8496 - val_loss: 0.4555 - val_accuracy: 0.7884\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8449 - val_loss: 0.4600 - val_accuracy: 0.7884\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8478 - val_loss: 0.4446 - val_accuracy: 0.7857\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8446 - val_loss: 0.4488 - val_accuracy: 0.7884\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8499 - val_loss: 0.4622 - val_accuracy: 0.7751\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.8572 - val_loss: 0.4513 - val_accuracy: 0.7884\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8522 - val_loss: 0.4510 - val_accuracy: 0.7963\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8519 - val_loss: 0.4612 - val_accuracy: 0.7831\n",
      "Epoch 32/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8593 - val_loss: 0.4586 - val_accuracy: 0.7804\n",
      "Epoch 33/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3175 - accuracy: 0.8658 - val_loss: 0.4509 - val_accuracy: 0.7857\n",
      "Epoch 34/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8634 - val_loss: 0.4523 - val_accuracy: 0.7910\n",
      "Epoch 35/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8587 - val_loss: 0.4571 - val_accuracy: 0.7937\n",
      "Epoch 36/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8634 - val_loss: 0.4543 - val_accuracy: 0.7910\n",
      "Epoch 37/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8678 - val_loss: 0.4533 - val_accuracy: 0.7989\n",
      "Epoch 38/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8708 - val_loss: 0.4494 - val_accuracy: 0.7937\n",
      "Epoch 39/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8714 - val_loss: 0.4522 - val_accuracy: 0.7989\n",
      "Epoch 40/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8717 - val_loss: 0.4740 - val_accuracy: 0.7831\n",
      "Test Accuracy: 78.30687761306763\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.6544 - val_loss: 0.5762 - val_accuracy: 0.7169\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.5280 - accuracy: 0.7421 - val_loss: 0.5352 - val_accuracy: 0.7090\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7657 - val_loss: 0.5035 - val_accuracy: 0.7487\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7936 - val_loss: 0.4951 - val_accuracy: 0.7619\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7931 - val_loss: 0.4850 - val_accuracy: 0.7619\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8081 - val_loss: 0.5104 - val_accuracy: 0.7513\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8022 - val_loss: 0.4819 - val_accuracy: 0.7619\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8145 - val_loss: 0.4846 - val_accuracy: 0.7778\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8175 - val_loss: 0.4767 - val_accuracy: 0.7804\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8110 - val_loss: 0.4771 - val_accuracy: 0.7857\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8204 - val_loss: 0.4764 - val_accuracy: 0.7831\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8213 - val_loss: 0.4794 - val_accuracy: 0.7831\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8231 - val_loss: 0.4834 - val_accuracy: 0.7751\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8210 - val_loss: 0.4831 - val_accuracy: 0.7725\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8269 - val_loss: 0.4786 - val_accuracy: 0.7831\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8201 - val_loss: 0.4787 - val_accuracy: 0.7831\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8322 - val_loss: 0.4785 - val_accuracy: 0.7725\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8254 - val_loss: 0.4751 - val_accuracy: 0.7831\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8322 - val_loss: 0.4771 - val_accuracy: 0.7831\n",
      "Epoch 20/40\n",
      " 91/107 [========================>.....] - ETA: 0s - loss: 0.3628 - accuracy: 0.8389Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8378 - val_loss: 0.4796 - val_accuracy: 0.7751\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 78.57142686843872\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6582 - val_loss: 0.5585 - val_accuracy: 0.6931\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7298 - val_loss: 0.5028 - val_accuracy: 0.7513\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7751 - val_loss: 0.4778 - val_accuracy: 0.7540\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7810 - val_loss: 0.4646 - val_accuracy: 0.7619\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8016 - val_loss: 0.4540 - val_accuracy: 0.7619\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8007 - val_loss: 0.4495 - val_accuracy: 0.7646\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8072 - val_loss: 0.4669 - val_accuracy: 0.7698\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8104 - val_loss: 0.4422 - val_accuracy: 0.7672\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8125 - val_loss: 0.4400 - val_accuracy: 0.7725\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8160 - val_loss: 0.4377 - val_accuracy: 0.7857\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8193 - val_loss: 0.4363 - val_accuracy: 0.7910\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8207 - val_loss: 0.4317 - val_accuracy: 0.7804\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8225 - val_loss: 0.4411 - val_accuracy: 0.7831\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8307 - val_loss: 0.4286 - val_accuracy: 0.7937\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8248 - val_loss: 0.4278 - val_accuracy: 0.7910\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8287 - val_loss: 0.4279 - val_accuracy: 0.7857\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8310 - val_loss: 0.4392 - val_accuracy: 0.7910\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8357 - val_loss: 0.4382 - val_accuracy: 0.7963\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8363 - val_loss: 0.4314 - val_accuracy: 0.7989\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8384 - val_loss: 0.4268 - val_accuracy: 0.7989\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8422 - val_loss: 0.4342 - val_accuracy: 0.8122\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8457 - val_loss: 0.4269 - val_accuracy: 0.7963\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8469 - val_loss: 0.4264 - val_accuracy: 0.8069\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8440 - val_loss: 0.4188 - val_accuracy: 0.8069\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8490 - val_loss: 0.4314 - val_accuracy: 0.8069\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8537 - val_loss: 0.4283 - val_accuracy: 0.8069\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8555 - val_loss: 0.4236 - val_accuracy: 0.8016\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8572 - val_loss: 0.4206 - val_accuracy: 0.7989\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8510 - val_loss: 0.4208 - val_accuracy: 0.7884\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8560 - val_loss: 0.4165 - val_accuracy: 0.8069\n",
      "Epoch 31/40\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.3227 - accuracy: 0.8606Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8608 - val_loss: 0.4251 - val_accuracy: 0.8016\n",
      "Epoch 00031: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6081 - accuracy: 0.6600 - val_loss: 0.5417 - val_accuracy: 0.6905\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7392 - val_loss: 0.4868 - val_accuracy: 0.7857\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7754 - val_loss: 0.4699 - val_accuracy: 0.7566\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7878 - val_loss: 0.4477 - val_accuracy: 0.8069\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7892 - val_loss: 0.4380 - val_accuracy: 0.7937\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8037 - val_loss: 0.4304 - val_accuracy: 0.7963\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8034 - val_loss: 0.4303 - val_accuracy: 0.8122\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8063 - val_loss: 0.4269 - val_accuracy: 0.8042\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8092 - val_loss: 0.4223 - val_accuracy: 0.8122\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8166 - val_loss: 0.4204 - val_accuracy: 0.8016\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8175 - val_loss: 0.4284 - val_accuracy: 0.8016\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8204 - val_loss: 0.4216 - val_accuracy: 0.8042\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8190 - val_loss: 0.4154 - val_accuracy: 0.7989\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8246 - val_loss: 0.4223 - val_accuracy: 0.7989\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8225 - val_loss: 0.4163 - val_accuracy: 0.7937\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8284 - val_loss: 0.4139 - val_accuracy: 0.7989\n",
      "Epoch 17/40\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.3736 - accuracy: 0.8318Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8307 - val_loss: 0.4167 - val_accuracy: 0.8016\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.6192 - accuracy: 0.6409 - val_loss: 0.5438 - val_accuracy: 0.7328\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7392 - val_loss: 0.4908 - val_accuracy: 0.7910\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7683 - val_loss: 0.4698 - val_accuracy: 0.7884\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4394 - val_accuracy: 0.8175\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7919 - val_loss: 0.4328 - val_accuracy: 0.8016\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8025 - val_loss: 0.4212 - val_accuracy: 0.8254\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7954 - val_loss: 0.4154 - val_accuracy: 0.8201\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8134 - val_loss: 0.4126 - val_accuracy: 0.8069\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8025 - val_loss: 0.4069 - val_accuracy: 0.8228\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8075 - val_loss: 0.4101 - val_accuracy: 0.8095\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8110 - val_loss: 0.4020 - val_accuracy: 0.8122\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8172 - val_loss: 0.4013 - val_accuracy: 0.8175\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8160 - val_loss: 0.4122 - val_accuracy: 0.7963\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8237 - val_loss: 0.3971 - val_accuracy: 0.8175\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8175 - val_loss: 0.4001 - val_accuracy: 0.8122\n",
      "Epoch 16/40\n",
      " 99/107 [==========================>...] - ETA: 0s - loss: 0.3825 - accuracy: 0.8258Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8254 - val_loss: 0.4077 - val_accuracy: 0.7989\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 82.53968358039856\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.6413 - val_loss: 0.5630 - val_accuracy: 0.6817\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7357 - val_loss: 0.5141 - val_accuracy: 0.7109\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7669 - val_loss: 0.4823 - val_accuracy: 0.7692\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7790 - val_loss: 0.4705 - val_accuracy: 0.7905\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7975 - val_loss: 0.4642 - val_accuracy: 0.7905\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7990 - val_loss: 0.4582 - val_accuracy: 0.7905\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8105 - val_loss: 0.4539 - val_accuracy: 0.7772\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8022 - val_loss: 0.4568 - val_accuracy: 0.7958\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8111 - val_loss: 0.4521 - val_accuracy: 0.7745\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8134 - val_loss: 0.4495 - val_accuracy: 0.7905\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8152 - val_loss: 0.4441 - val_accuracy: 0.7878\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8190 - val_loss: 0.4476 - val_accuracy: 0.7798\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8196 - val_loss: 0.4434 - val_accuracy: 0.7958\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8267 - val_loss: 0.4417 - val_accuracy: 0.7905\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8290 - val_loss: 0.4417 - val_accuracy: 0.7931\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8284 - val_loss: 0.4360 - val_accuracy: 0.7958\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8281 - val_loss: 0.4382 - val_accuracy: 0.7851\n",
      "Epoch 18/40\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.3700 - accuracy: 0.8270Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8293 - val_loss: 0.4371 - val_accuracy: 0.7905\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.6527 - val_loss: 0.5528 - val_accuracy: 0.7480\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7313 - val_loss: 0.4922 - val_accuracy: 0.7878\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7655 - val_loss: 0.4606 - val_accuracy: 0.7931\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7849 - val_loss: 0.4520 - val_accuracy: 0.7825\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7887 - val_loss: 0.4411 - val_accuracy: 0.7851\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8034 - val_loss: 0.4378 - val_accuracy: 0.7931\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8019 - val_loss: 0.4488 - val_accuracy: 0.7692\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8037 - val_loss: 0.4334 - val_accuracy: 0.7958\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8084 - val_loss: 0.4337 - val_accuracy: 0.7958\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8155 - val_loss: 0.4324 - val_accuracy: 0.8011\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8181 - val_loss: 0.4332 - val_accuracy: 0.7825\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8187 - val_loss: 0.4341 - val_accuracy: 0.7851\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8220 - val_loss: 0.4320 - val_accuracy: 0.7905\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8234 - val_loss: 0.4293 - val_accuracy: 0.7851\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8264 - val_loss: 0.4398 - val_accuracy: 0.7798\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8267 - val_loss: 0.4378 - val_accuracy: 0.7772\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8320 - val_loss: 0.4418 - val_accuracy: 0.7666\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8337 - val_loss: 0.4331 - val_accuracy: 0.7798\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8370 - val_loss: 0.4330 - val_accuracy: 0.7772\n",
      "Epoch 20/40\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.3600 - accuracy: 0.8414Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8390 - val_loss: 0.4375 - val_accuracy: 0.7692\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6474 - val_loss: 0.5555 - val_accuracy: 0.6897\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7216 - val_loss: 0.4941 - val_accuracy: 0.7905\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7749 - val_loss: 0.4675 - val_accuracy: 0.7984\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7828 - val_loss: 0.4562 - val_accuracy: 0.8011\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7958 - val_loss: 0.4431 - val_accuracy: 0.8223\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7978 - val_loss: 0.4514 - val_accuracy: 0.7851\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8064 - val_loss: 0.4350 - val_accuracy: 0.8011\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8099 - val_loss: 0.4435 - val_accuracy: 0.7798\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8119 - val_loss: 0.4317 - val_accuracy: 0.8011\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8193 - val_loss: 0.4274 - val_accuracy: 0.8064\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8199 - val_loss: 0.4213 - val_accuracy: 0.8196\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8155 - val_loss: 0.4263 - val_accuracy: 0.7931\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8175 - val_loss: 0.4170 - val_accuracy: 0.8170\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8228 - val_loss: 0.4184 - val_accuracy: 0.8117\n",
      "Epoch 15/40\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.3812 - accuracy: 0.8262Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8252 - val_loss: 0.4211 - val_accuracy: 0.8011\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 82.22811818122864\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.6524 - val_loss: 0.5463 - val_accuracy: 0.6897\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7222 - val_loss: 0.4892 - val_accuracy: 0.7480\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7690 - val_loss: 0.4566 - val_accuracy: 0.7931\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7731 - val_loss: 0.4346 - val_accuracy: 0.7878\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7896 - val_loss: 0.4443 - val_accuracy: 0.7878\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8016 - val_loss: 0.4162 - val_accuracy: 0.7931\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7993 - val_loss: 0.4147 - val_accuracy: 0.7905\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8096 - val_loss: 0.4228 - val_accuracy: 0.7958\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8117 - val_loss: 0.4043 - val_accuracy: 0.7984\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8114 - val_loss: 0.4002 - val_accuracy: 0.8011\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8143 - val_loss: 0.3987 - val_accuracy: 0.8037\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8222 - val_loss: 0.4014 - val_accuracy: 0.7905\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8217 - val_loss: 0.3962 - val_accuracy: 0.8037\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8181 - val_loss: 0.3963 - val_accuracy: 0.7984\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8296 - val_loss: 0.3952 - val_accuracy: 0.8090\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8290 - val_loss: 0.4045 - val_accuracy: 0.7931\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8258 - val_loss: 0.3942 - val_accuracy: 0.8011\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8320 - val_loss: 0.3870 - val_accuracy: 0.8117\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8328 - val_loss: 0.4000 - val_accuracy: 0.8037\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8364 - val_loss: 0.3979 - val_accuracy: 0.8011\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8384 - val_loss: 0.3904 - val_accuracy: 0.8117\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8408 - val_loss: 0.3970 - val_accuracy: 0.7984\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8420 - val_loss: 0.3888 - val_accuracy: 0.8064\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8464 - val_loss: 0.3880 - val_accuracy: 0.8011\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8464 - val_loss: 0.3945 - val_accuracy: 0.8037\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8473 - val_loss: 0.3859 - val_accuracy: 0.8170\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8520 - val_loss: 0.3925 - val_accuracy: 0.8011\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8449 - val_loss: 0.3869 - val_accuracy: 0.7958\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8523 - val_loss: 0.3877 - val_accuracy: 0.8117\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8558 - val_loss: 0.3900 - val_accuracy: 0.8011\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8546 - val_loss: 0.3869 - val_accuracy: 0.8064\n",
      "Epoch 32/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8579 - val_loss: 0.3881 - val_accuracy: 0.8064\n",
      "Epoch 33/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8514 - val_loss: 0.3915 - val_accuracy: 0.7958\n",
      "Epoch 34/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8602 - val_loss: 0.3856 - val_accuracy: 0.8143\n",
      "Epoch 35/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8640 - val_loss: 0.4034 - val_accuracy: 0.8011\n",
      "Epoch 36/40\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.8652Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8652 - val_loss: 0.3889 - val_accuracy: 0.8143\n",
      "Epoch 00036: early stopping\n",
      "Test Accuracy: 81.69761300086975\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6065 - accuracy: 0.6524 - val_loss: 0.5977 - val_accuracy: 0.6552\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7307 - val_loss: 0.5490 - val_accuracy: 0.7082\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7702 - val_loss: 0.5184 - val_accuracy: 0.7454\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7878 - val_loss: 0.5091 - val_accuracy: 0.7639\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8011 - val_loss: 0.5124 - val_accuracy: 0.7454\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8034 - val_loss: 0.5034 - val_accuracy: 0.7586\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8152 - val_loss: 0.4966 - val_accuracy: 0.7613\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8164 - val_loss: 0.4959 - val_accuracy: 0.7692\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8199 - val_loss: 0.5012 - val_accuracy: 0.7454\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8164 - val_loss: 0.4843 - val_accuracy: 0.7905\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8240 - val_loss: 0.4886 - val_accuracy: 0.7825\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8193 - val_loss: 0.4882 - val_accuracy: 0.7772\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8267 - val_loss: 0.4890 - val_accuracy: 0.7825\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8302 - val_loss: 0.5008 - val_accuracy: 0.7533\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8284 - val_loss: 0.5082 - val_accuracy: 0.7533\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8337 - val_loss: 0.4869 - val_accuracy: 0.7905\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8402 - val_loss: 0.5084 - val_accuracy: 0.7560\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8434 - val_loss: 0.4923 - val_accuracy: 0.7745\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8426 - val_loss: 0.4827 - val_accuracy: 0.7825\n",
      "Epoch 20/40\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.3511 - accuracy: 0.8426Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8428 - val_loss: 0.4956 - val_accuracy: 0.7719\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
      "0  78.306878  78.571427  81.216931  81.216931  82.539684  79.575598   \n",
      "\n",
      "        acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.106103  82.228118  81.697613  79.045093  80.450438  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Obtain the word to index\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model_2(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record2 = record2.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.306878</td>\n",
       "      <td>78.571427</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>82.539684</td>\n",
       "      <td>79.575598</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>82.228118</td>\n",
       "      <td>81.697613</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>80.450438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
       "0  78.306878  78.571427  81.216931  81.216931  82.539684  79.575598   \n",
       "\n",
       "        acc7       acc8       acc9      acc10        AVG  \n",
       "0  80.106103  82.228118  81.697613  79.045093  80.450438  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2\n",
    "report = report.to_excel('Emb_MLP_CR_2.xlsx', sheet_name='model_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_3(input_length=300):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense( units=100, activation='relu', input_shape=(input_length,)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=50, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense( units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 35,201\n",
      "Trainable params: 35,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = define_model_3(300)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=1, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6287 - accuracy: 0.6417 - val_loss: 0.5969 - val_accuracy: 0.6296\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7103 - val_loss: 0.5277 - val_accuracy: 0.7328\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7616 - val_loss: 0.4848 - val_accuracy: 0.7487\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7798 - val_loss: 0.4576 - val_accuracy: 0.7831\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7913 - val_loss: 0.4475 - val_accuracy: 0.7804\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8019 - val_loss: 0.4453 - val_accuracy: 0.7857\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8048 - val_loss: 0.4396 - val_accuracy: 0.7910\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8169 - val_loss: 0.4450 - val_accuracy: 0.7751\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8178 - val_loss: 0.4431 - val_accuracy: 0.7910\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8187 - val_loss: 0.4354 - val_accuracy: 0.7857\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8313 - val_loss: 0.4379 - val_accuracy: 0.7778\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8334 - val_loss: 0.4296 - val_accuracy: 0.7937\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8387 - val_loss: 0.4306 - val_accuracy: 0.7910\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8404 - val_loss: 0.4383 - val_accuracy: 0.7751\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8428 - val_loss: 0.4373 - val_accuracy: 0.7884\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8452 - val_loss: 0.4341 - val_accuracy: 0.8069\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8513 - val_loss: 0.4331 - val_accuracy: 0.8122\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8510 - val_loss: 0.4411 - val_accuracy: 0.7989\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8584 - val_loss: 0.4367 - val_accuracy: 0.7963\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8669 - val_loss: 0.4574 - val_accuracy: 0.7857\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8784 - val_loss: 0.4771 - val_accuracy: 0.7804\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8661 - val_loss: 0.4665 - val_accuracy: 0.7910\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2952 - accuracy: 0.8770 - val_loss: 0.4621 - val_accuracy: 0.7989\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8690 - val_loss: 0.4435 - val_accuracy: 0.8069\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.8808 - val_loss: 0.4628 - val_accuracy: 0.8122\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8875 - val_loss: 0.4784 - val_accuracy: 0.7989\n",
      "Epoch 27/40\n",
      " 83/107 [======================>.......] - ETA: 0s - loss: 0.2722 - accuracy: 0.8855Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.8878 - val_loss: 0.4634 - val_accuracy: 0.8095\n",
      "Epoch 00027: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6245 - accuracy: 0.6420 - val_loss: 0.5678 - val_accuracy: 0.6614\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7192 - val_loss: 0.4916 - val_accuracy: 0.7407\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7654 - val_loss: 0.4635 - val_accuracy: 0.7831\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7839 - val_loss: 0.4696 - val_accuracy: 0.7566\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7984 - val_loss: 0.4660 - val_accuracy: 0.7751\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8075 - val_loss: 0.4498 - val_accuracy: 0.7831\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8151 - val_loss: 0.4531 - val_accuracy: 0.7725\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8172 - val_loss: 0.4555 - val_accuracy: 0.7751\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8178 - val_loss: 0.4492 - val_accuracy: 0.7804\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8172 - val_loss: 0.4502 - val_accuracy: 0.7778\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8319 - val_loss: 0.4640 - val_accuracy: 0.7804\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8349 - val_loss: 0.4568 - val_accuracy: 0.7804\n",
      "Epoch 13/40\n",
      "104/107 [============================>.] - ETA: 0s - loss: 0.3713 - accuracy: 0.8356Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8351 - val_loss: 0.4661 - val_accuracy: 0.7751\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 78.30687761306763\n",
      "\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6295 - accuracy: 0.6414 - val_loss: 0.5648 - val_accuracy: 0.6640\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7248 - val_loss: 0.4914 - val_accuracy: 0.7407\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7560 - val_loss: 0.4722 - val_accuracy: 0.7487\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7822 - val_loss: 0.4619 - val_accuracy: 0.7566\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7928 - val_loss: 0.4628 - val_accuracy: 0.7619\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8075 - val_loss: 0.4505 - val_accuracy: 0.7725\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8028 - val_loss: 0.4590 - val_accuracy: 0.7698\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8122 - val_loss: 0.4548 - val_accuracy: 0.7646\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8181 - val_loss: 0.4458 - val_accuracy: 0.7698\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8193 - val_loss: 0.4591 - val_accuracy: 0.7698\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8298 - val_loss: 0.4492 - val_accuracy: 0.7698\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8325 - val_loss: 0.4586 - val_accuracy: 0.7672\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8254 - val_loss: 0.4579 - val_accuracy: 0.7619\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8363 - val_loss: 0.4598 - val_accuracy: 0.7566\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8413 - val_loss: 0.4512 - val_accuracy: 0.7646\n",
      "Epoch 16/40\n",
      " 89/107 [=======================>......] - ETA: 0s - loss: 0.3582 - accuracy: 0.8385Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8381 - val_loss: 0.4540 - val_accuracy: 0.7540\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 77.24867463111877\n",
      "\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6380 - accuracy: 0.6247 - val_loss: 0.5559 - val_accuracy: 0.6878\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7136 - val_loss: 0.4681 - val_accuracy: 0.7672\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7645 - val_loss: 0.4396 - val_accuracy: 0.7989\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7780 - val_loss: 0.4185 - val_accuracy: 0.7857\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7878 - val_loss: 0.4197 - val_accuracy: 0.7778\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7936 - val_loss: 0.4104 - val_accuracy: 0.7937\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8034 - val_loss: 0.4056 - val_accuracy: 0.8042\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8092 - val_loss: 0.4056 - val_accuracy: 0.7963\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8072 - val_loss: 0.3996 - val_accuracy: 0.8042\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8228 - val_loss: 0.4000 - val_accuracy: 0.8095\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8213 - val_loss: 0.4078 - val_accuracy: 0.8201\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8322 - val_loss: 0.4004 - val_accuracy: 0.8175\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8272 - val_loss: 0.4144 - val_accuracy: 0.8175\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8378 - val_loss: 0.4112 - val_accuracy: 0.8042\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8428 - val_loss: 0.4128 - val_accuracy: 0.8016\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8378 - val_loss: 0.4092 - val_accuracy: 0.8122\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8508 - val_loss: 0.4156 - val_accuracy: 0.8069\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8537 - val_loss: 0.4088 - val_accuracy: 0.8228\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8522 - val_loss: 0.4215 - val_accuracy: 0.8069\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8599 - val_loss: 0.4257 - val_accuracy: 0.8148\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8722 - val_loss: 0.4103 - val_accuracy: 0.8280\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8625 - val_loss: 0.4384 - val_accuracy: 0.8016\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8658 - val_loss: 0.4388 - val_accuracy: 0.8016\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8640 - val_loss: 0.4309 - val_accuracy: 0.8016\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8808 - val_loss: 0.4189 - val_accuracy: 0.8122\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8793 - val_loss: 0.4370 - val_accuracy: 0.8254\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8837 - val_loss: 0.4332 - val_accuracy: 0.7989\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.8887 - val_loss: 0.4423 - val_accuracy: 0.8148\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8867 - val_loss: 0.4356 - val_accuracy: 0.8122\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.8923 - val_loss: 0.4854 - val_accuracy: 0.7989\n",
      "Epoch 31/40\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.2440 - accuracy: 0.9016Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.8999 - val_loss: 0.4831 - val_accuracy: 0.7963\n",
      "Epoch 00031: early stopping\n",
      "Test Accuracy: 82.80423283576965\n",
      "\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6293 - accuracy: 0.6409 - val_loss: 0.5546 - val_accuracy: 0.6852\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7280 - val_loss: 0.4717 - val_accuracy: 0.7910\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7733 - val_loss: 0.4744 - val_accuracy: 0.7751\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7786 - val_loss: 0.4496 - val_accuracy: 0.8016\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7936 - val_loss: 0.4468 - val_accuracy: 0.8042\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.4555 - val_accuracy: 0.7910\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8037 - val_loss: 0.4787 - val_accuracy: 0.7804\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8072 - val_loss: 0.4569 - val_accuracy: 0.7989\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8210 - val_loss: 0.4608 - val_accuracy: 0.7989\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8131 - val_loss: 0.4782 - val_accuracy: 0.7804\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8140 - val_loss: 0.4517 - val_accuracy: 0.7937\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8257 - val_loss: 0.4596 - val_accuracy: 0.8016\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8301 - val_loss: 0.4634 - val_accuracy: 0.7857\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8334 - val_loss: 0.4744 - val_accuracy: 0.7725\n",
      "Epoch 15/40\n",
      " 81/107 [=====================>........] - ETA: 0s - loss: 0.3749 - accuracy: 0.8326Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8375 - val_loss: 0.4873 - val_accuracy: 0.7884\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6275 - accuracy: 0.6315 - val_loss: 0.5514 - val_accuracy: 0.7294\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7219 - val_loss: 0.4823 - val_accuracy: 0.7958\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7660 - val_loss: 0.4626 - val_accuracy: 0.7931\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7772 - val_loss: 0.4639 - val_accuracy: 0.7719\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7975 - val_loss: 0.4593 - val_accuracy: 0.7719\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8034 - val_loss: 0.4594 - val_accuracy: 0.7825\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8099 - val_loss: 0.4546 - val_accuracy: 0.7905\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8093 - val_loss: 0.4553 - val_accuracy: 0.7798\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8237 - val_loss: 0.4606 - val_accuracy: 0.7905\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8246 - val_loss: 0.4845 - val_accuracy: 0.7878\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8228 - val_loss: 0.4714 - val_accuracy: 0.8117\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8284 - val_loss: 0.4692 - val_accuracy: 0.7958\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8346 - val_loss: 0.4688 - val_accuracy: 0.7905\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8417 - val_loss: 0.4752 - val_accuracy: 0.7931\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8417 - val_loss: 0.4708 - val_accuracy: 0.7958\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8514 - val_loss: 0.4731 - val_accuracy: 0.8143\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8470 - val_loss: 0.4879 - val_accuracy: 0.7692\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8531 - val_loss: 0.4654 - val_accuracy: 0.8037\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8605 - val_loss: 0.4816 - val_accuracy: 0.7851\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8693 - val_loss: 0.5017 - val_accuracy: 0.7958\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8708 - val_loss: 0.4806 - val_accuracy: 0.7905\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.8761 - val_loss: 0.4911 - val_accuracy: 0.7878\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8793 - val_loss: 0.4903 - val_accuracy: 0.7958\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8811 - val_loss: 0.4951 - val_accuracy: 0.7931\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8891 - val_loss: 0.4960 - val_accuracy: 0.7905\n",
      "Epoch 26/40\n",
      " 80/107 [=====================>........] - ETA: 0s - loss: 0.2698 - accuracy: 0.8867Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8870 - val_loss: 0.5099 - val_accuracy: 0.7878\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6406 - accuracy: 0.6286 - val_loss: 0.5934 - val_accuracy: 0.6048\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7039 - val_loss: 0.4881 - val_accuracy: 0.7639\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7628 - val_loss: 0.4585 - val_accuracy: 0.7878\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7793 - val_loss: 0.4461 - val_accuracy: 0.7958\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7869 - val_loss: 0.4533 - val_accuracy: 0.7931\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8014 - val_loss: 0.4372 - val_accuracy: 0.7958\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8114 - val_loss: 0.4613 - val_accuracy: 0.7745\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8125 - val_loss: 0.4463 - val_accuracy: 0.7745\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8172 - val_loss: 0.4569 - val_accuracy: 0.7719\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8222 - val_loss: 0.4325 - val_accuracy: 0.8037\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8199 - val_loss: 0.4233 - val_accuracy: 0.7958\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8323 - val_loss: 0.4209 - val_accuracy: 0.7984\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8305 - val_loss: 0.4286 - val_accuracy: 0.7958\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8334 - val_loss: 0.4219 - val_accuracy: 0.7931\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8473 - val_loss: 0.4402 - val_accuracy: 0.7905\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8490 - val_loss: 0.4246 - val_accuracy: 0.7984\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8555 - val_loss: 0.4416 - val_accuracy: 0.8037\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8523 - val_loss: 0.4142 - val_accuracy: 0.8196\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8599 - val_loss: 0.4279 - val_accuracy: 0.8037\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8611 - val_loss: 0.4374 - val_accuracy: 0.8011\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3174 - accuracy: 0.8632 - val_loss: 0.4338 - val_accuracy: 0.8037\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8723 - val_loss: 0.4284 - val_accuracy: 0.8276\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8782 - val_loss: 0.4260 - val_accuracy: 0.8064\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8761 - val_loss: 0.4214 - val_accuracy: 0.8196\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8846 - val_loss: 0.4231 - val_accuracy: 0.8249\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.8832 - val_loss: 0.4267 - val_accuracy: 0.8223\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8867 - val_loss: 0.4370 - val_accuracy: 0.8143\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.8932 - val_loss: 0.4433 - val_accuracy: 0.8196\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.8967 - val_loss: 0.4601 - val_accuracy: 0.7931\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.8908 - val_loss: 0.4408 - val_accuracy: 0.8090\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.8961 - val_loss: 0.4487 - val_accuracy: 0.8249\n",
      "Epoch 32/40\n",
      " 85/107 [======================>.......] - ETA: 0s - loss: 0.2468 - accuracy: 0.8996Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.9008 - val_loss: 0.4727 - val_accuracy: 0.7984\n",
      "Epoch 00032: early stopping\n",
      "Test Accuracy: 82.75862336158752\n",
      "\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.6269 - accuracy: 0.6363 - val_loss: 0.5662 - val_accuracy: 0.7029\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7195 - val_loss: 0.4989 - val_accuracy: 0.7745\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7678 - val_loss: 0.4646 - val_accuracy: 0.7825\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7878 - val_loss: 0.4741 - val_accuracy: 0.7666\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7916 - val_loss: 0.4454 - val_accuracy: 0.7878\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7978 - val_loss: 0.4439 - val_accuracy: 0.7984\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8093 - val_loss: 0.4332 - val_accuracy: 0.8064\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8019 - val_loss: 0.4501 - val_accuracy: 0.7905\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8137 - val_loss: 0.4236 - val_accuracy: 0.8117\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8222 - val_loss: 0.4244 - val_accuracy: 0.8064\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8196 - val_loss: 0.4204 - val_accuracy: 0.8037\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8270 - val_loss: 0.4331 - val_accuracy: 0.7984\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8325 - val_loss: 0.4350 - val_accuracy: 0.7905\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8325 - val_loss: 0.4218 - val_accuracy: 0.7958\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8355 - val_loss: 0.4518 - val_accuracy: 0.7958\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8455 - val_loss: 0.4477 - val_accuracy: 0.8037\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8479 - val_loss: 0.4367 - val_accuracy: 0.7958\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8540 - val_loss: 0.4479 - val_accuracy: 0.8011\n",
      "Epoch 19/40\n",
      "105/107 [============================>.] - ETA: 0s - loss: 0.3281 - accuracy: 0.8583Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8576 - val_loss: 0.4591 - val_accuracy: 0.7586\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6231 - accuracy: 0.6454 - val_loss: 0.5814 - val_accuracy: 0.6897\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7192 - val_loss: 0.5219 - val_accuracy: 0.7241\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7663 - val_loss: 0.4870 - val_accuracy: 0.7560\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7840 - val_loss: 0.4783 - val_accuracy: 0.7639\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7949 - val_loss: 0.4847 - val_accuracy: 0.7586\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8064 - val_loss: 0.4908 - val_accuracy: 0.7586\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8093 - val_loss: 0.4618 - val_accuracy: 0.7666\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8049 - val_loss: 0.4666 - val_accuracy: 0.7851\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8170 - val_loss: 0.4898 - val_accuracy: 0.7533\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8258 - val_loss: 0.4713 - val_accuracy: 0.7586\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8305 - val_loss: 0.4904 - val_accuracy: 0.7692\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8317 - val_loss: 0.4567 - val_accuracy: 0.7745\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8343 - val_loss: 0.4550 - val_accuracy: 0.7745\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8299 - val_loss: 0.4515 - val_accuracy: 0.7798\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8411 - val_loss: 0.4854 - val_accuracy: 0.7719\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8464 - val_loss: 0.4809 - val_accuracy: 0.7666\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8470 - val_loss: 0.4948 - val_accuracy: 0.7745\n",
      "Epoch 18/40\n",
      "100/107 [===========================>..] - ETA: 0s - loss: 0.3423 - accuracy: 0.8444Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8452 - val_loss: 0.4861 - val_accuracy: 0.7719\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.6320 - accuracy: 0.6366 - val_loss: 0.5565 - val_accuracy: 0.6525\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7251 - val_loss: 0.4681 - val_accuracy: 0.7772\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7631 - val_loss: 0.4337 - val_accuracy: 0.8064\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7846 - val_loss: 0.4184 - val_accuracy: 0.8037\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7869 - val_loss: 0.4143 - val_accuracy: 0.7931\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7884 - val_loss: 0.4125 - val_accuracy: 0.7905\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8043 - val_loss: 0.4059 - val_accuracy: 0.8011\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8093 - val_loss: 0.4023 - val_accuracy: 0.7984\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8131 - val_loss: 0.3970 - val_accuracy: 0.7878\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8249 - val_loss: 0.4027 - val_accuracy: 0.8011\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8252 - val_loss: 0.4273 - val_accuracy: 0.7878\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8340 - val_loss: 0.4042 - val_accuracy: 0.8064\n",
      "Epoch 13/40\n",
      " 99/107 [==========================>...] - ETA: 0s - loss: 0.3792 - accuracy: 0.8330Restoring model weights from the end of the best epoch.\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8355 - val_loss: 0.3969 - val_accuracy: 0.8037\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5      acc6       acc7  \\\n",
      "0  81.216931  78.306878  77.248675  82.804233  80.423278  81.43236  82.758623   \n",
      "\n",
      "        acc8       acc9      acc10        AVG  \n",
      "0  81.167108  78.514588  80.636603  80.450928  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "oov_tok = \"<UNK>\"\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the data into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    # Define the word_index\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    # Clean the sentences\n",
    "    Xtrain = clean_doc(train_x, word_index)\n",
    "    Xtest = clean_doc(test_x, word_index)\n",
    "\n",
    "    # Encode the sentences into word embedding average representation\n",
    "    Xtrain = encoded_sentences(Xtrain)\n",
    "    Xtest = encoded_sentences(Xtest)\n",
    "    \n",
    "    # Define the input shape\n",
    "    model = define_model_3(Xtrain.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "    print()\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record3 = record3.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record3)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.216931</td>\n",
       "      <td>78.306878</td>\n",
       "      <td>77.248675</td>\n",
       "      <td>82.804233</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>81.43236</td>\n",
       "      <td>82.758623</td>\n",
       "      <td>81.167108</td>\n",
       "      <td>78.514588</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>80.450928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5      acc6       acc7  \\\n",
       "0  81.216931  78.306878  77.248675  82.804233  80.423278  81.43236  82.758623   \n",
       "\n",
       "        acc8       acc9      acc10        AVG  \n",
       "0  81.167108  78.514588  80.636603  80.450928  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3\n",
    "report = report.to_excel('Emb_MLP_CR_3.xlsx', sheet_name='model_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
